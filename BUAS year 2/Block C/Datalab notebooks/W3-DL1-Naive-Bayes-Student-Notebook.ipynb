{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "municipal-caribbean",
   "metadata": {},
   "source": [
    "In this DataLab you will implement a Naive Bayes classifier as described in Chapter 4 of the book Speech and Language Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acknowledged-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import re                                  \n",
    "import string  \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controversial-heather",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\neilr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bottom-contract",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\neilr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naval-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "historic-description",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets:  5000\n",
      "Number of negative tweets:  5000\n",
      "\n",
      "The type of all_positive_tweets is:  <class 'list'>\n",
      "The type of a tweet entry is:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive tweets: ', len(all_positive_tweets))\n",
    "print('Number of negative tweets: ', len(all_negative_tweets))\n",
    "\n",
    "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
    "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "undefined-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m@Gurmeetramrahim #OurDaughtersOurPride dhan dhan satguru tera hi aasra...many congratulations Pita G...Keep them blessed as always :-)\n",
      "\u001b[91m@GABRlEIIE not as much as my brother :(\n"
     ]
    }
   ],
   "source": [
    "# print positive in greeen\n",
    "print('\\033[92m' + all_positive_tweets[random.randint(0,5000)])\n",
    "\n",
    "# print negative in red\n",
    "print('\\033[91m' + all_negative_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-determination",
   "metadata": {},
   "source": [
    "**Tweet preprocessing**\n",
    "\n",
    "Last week you learned how to use regular expressions to process tweets. Use the function `tweet_processor()` you created in the last DataLab here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "selected-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a list of token\n",
    "        \n",
    "    Processing steps:\n",
    "    - Removes hyperlinks\n",
    "    - Removes # sign\n",
    "    - Tokenizes\n",
    "    - Removes stopwords and punctuation\n",
    "    - Stem tokens\n",
    "        \n",
    "    \"\"\"\n",
    "    # Remove URLs using regular expression\n",
    "    processed_tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    processed_tweet = re.sub(r'#([^\\s]+)', r'\\1', processed_tweet)\n",
    "    \n",
    "    # Tokenize the tweet using TweetTokenizer\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=False)\n",
    "    processed_tweet = tokenizer.tokenize(processed_tweet)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stopwords_english = set(stopwords.words('english'))\n",
    "    processed_tweet = [word for word in processed_tweet if word not in stopwords_english]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    processed_tweet = [word for word in processed_tweet if word not in string.punctuation]\n",
    "    \n",
    "    # Stem the tokens\n",
    "    stemmer = PorterStemmer()\n",
    "    processed_tweet = [stemmer.stem(word) for word in processed_tweet]\n",
    "\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-thriller",
   "metadata": {},
   "source": [
    "And sanity check if it works.\n",
    "    \n",
    "Example tweet:\n",
    "    \n",
    "`My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i`\n",
    "\n",
    "Expected output:\n",
    "\n",
    "`['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '…']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "right-notebook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i\n"
     ]
    }
   ],
   "source": [
    "example_tweet = ('My beautiful sunflowers on a sunny Friday morning off :)'\n",
    "                 ' #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i')\n",
    "print(example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wrapped-courage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beauti',\n",
       " 'sunflow',\n",
       " 'sunni',\n",
       " 'friday',\n",
       " 'morn',\n",
       " ':)',\n",
       " 'sunflow',\n",
       " 'favourit',\n",
       " 'happi',\n",
       " 'friday',\n",
       " '…']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_processor(example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-assurance",
   "metadata": {},
   "source": [
    "Before going any further, let's split the dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compound-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% training 20% testing\n",
    "positive_tweets_tr = all_positive_tweets[:4000]\n",
    "positive_tweets_te = all_positive_tweets[4000:]\n",
    "\n",
    "negative_tweets_tr = all_negative_tweets[:4000]\n",
    "negative_tweets_te = all_negative_tweets[4000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-jonathan",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "\n",
    "The function `tweet_processor()` expects a single tweet to process. But you have lists of tweets to process. Write a function called `tweet_processor_list()` that accept a list of strings (tweets) and returns a list of processed tweets. A processed tweet is a list of tokens. Therefore  `tweet_processor_list()` should return a list of lists.\n",
    "\n",
    "The first two items in the `positive_tweets_tr` are:\n",
    "\n",
    "```\n",
    "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
    " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!']\n",
    " ```\n",
    " \n",
    " the expected output of `tweet_processor_list()` is:\n",
    " \n",
    " ```\n",
    " [['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)'],\n",
    " ['hey',\n",
    "  'jame',\n",
    "  'odd',\n",
    "  ':/',\n",
    "  'pleas',\n",
    "  'call',\n",
    "  'contact',\n",
    "  'centr',\n",
    "  '02392441234',\n",
    "  'abl',\n",
    "  'assist',\n",
    "  ':)',\n",
    "  'mani',\n",
    "  'thank']]\n",
    " \n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "virgin-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor_list(tweet_list):\n",
    "    # YOUR CODE HERE #\n",
    "    processed_tweet_list = []\n",
    "    for tweet in tweet_list:\n",
    "        processed_tweet = tweet_processor(tweet)\n",
    "        processed_tweet_list.append(processed_tweet)\n",
    "    return processed_tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "emerging-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets_tr = tweet_processor_list(positive_tweets_tr)\n",
    "positive_tweets_te = tweet_processor_list(positive_tweets_te)\n",
    "\n",
    "negative_tweets_tr = tweet_processor_list(negative_tweets_tr)\n",
    "negative_tweets_te = tweet_processor_list(negative_tweets_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-playing",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Now it is time to creative the _vocabulary_ as defined in Chapter 4, Section 4.2:\n",
    "\n",
    "> vocabulary V consists of the union of all the word types in all classes\n",
    "\n",
    "Combine all the tokens in `positive_tweets_tr` and `negative_tweets_tr` into one big list and get the unique tokens from this list.\n",
    "\n",
    "Expected length of the vocabulary is `9085` unique tokens. Notice that if you use a different train/test split or different preprocessing this number will be different.\n",
    "\n",
    "First 50 tokens in the vocabulary:\n",
    "\n",
    "```\n",
    "['(-:',\n",
    " '(:',\n",
    " '):',\n",
    " '--->',\n",
    " '-->',\n",
    " '->',\n",
    " '.\\n.',\n",
    " '.\\n.\\n.',\n",
    " '. .',\n",
    " '. . .',\n",
    " '. ..',\n",
    " '. ...',\n",
    " '..',\n",
    " '...',\n",
    " '0',\n",
    " '0-100',\n",
    " '0-2',\n",
    " '0.001',\n",
    " '0.7',\n",
    " '00',\n",
    " '00128835',\n",
    " '009',\n",
    " '00962778381',\n",
    " '01282',\n",
    " '01482',\n",
    " '01:15',\n",
    " '01:16',\n",
    " '02079',\n",
    " '02392441234',\n",
    " '0272 3306',\n",
    " '0330 333 7234',\n",
    " '0345',\n",
    " '05.15',\n",
    " '07:02',\n",
    " '07:17',\n",
    " '07:24',\n",
    " '07:25',\n",
    " '07:32',\n",
    " '07:34',\n",
    " '08',\n",
    " '0878 0388',\n",
    " '08962464174',\n",
    " '0ne',\n",
    " '1',\n",
    " '1,300',\n",
    " '1,500',\n",
    " '1-0',\n",
    " '1.300',\n",
    " '1.8',\n",
    " '1/2']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eligible-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary: 14884\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE #\n",
    "# Combine all tokens from positive_tweets_tr and negative_tweets_tr\n",
    "all_tweets = positive_tweets_tr + negative_tweets_tr\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "all_tokens = [token for tweet in all_tweets for token in tweet]\n",
    "\n",
    "# Get unique tokens\n",
    "vocabulary = list(set(all_tokens))\n",
    "\n",
    "# Sort the vocabulary for consistency\n",
    "vocabulary.sort()\n",
    "\n",
    "# Print the length of the vocabulary\n",
    "print(\"Length of vocabulary:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-things",
   "metadata": {},
   "source": [
    "**Task 3**\n",
    "\n",
    "In order to calculate the equation 4.12\n",
    "\n",
    "$P(w_i|c)=count(w_i, c)/\\Sigma_{w∈V} count(w, c)$\n",
    "\n",
    "We first need to calculate $count(w_i, c)$ which is the number of times each token in the vocabulary occurs in tweets from class c. This is also called the word frequency table.\n",
    "\n",
    "|$w_i$| count($w_i$, +) | count($w_i$, -) |\n",
    "| ----------- | ----------- |----------- |\n",
    "|(-:|1|0|\n",
    "|(:|1|6|\n",
    "|):|6|6|\n",
    "|--->|1|0|\n",
    "|happi|161|18|\n",
    "\n",
    "\n",
    "First create a dictionary called `freq` where keys are tokens and values are lists containing positive and negative counts\n",
    "\n",
    "```\n",
    "{'(-:': [1, 0],\n",
    " '(:': [1, 6],\n",
    " ...\n",
    "}\n",
    "```\n",
    "\n",
    "and convert it to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "level-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store frequencies\n",
    "freqs = {}\n",
    "\n",
    "# Iterate over all tokens in the vocabulary\n",
    "for token in vocabulary:\n",
    "    # Initialize counts for positive and negative tweets\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    \n",
    "    # Iterate over all positive tweets and count occurrences of the token\n",
    "    for tweet in positive_tweets_tr:\n",
    "        if token in tweet:\n",
    "            positive_count += 1\n",
    "    \n",
    "    # Iterate over all negative tweets and count occurrences of the token\n",
    "    for tweet in negative_tweets_tr:\n",
    "        if token in tweet:\n",
    "            negative_count += 1\n",
    "    \n",
    "    # Add counts to the freqs dictionary\n",
    "    freqs[token] = [positive_count, negative_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "raised-tuesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(w_i, +)</th>\n",
       "      <th>count(w_i, -)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#bbmme</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#segalakatakata</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-:</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(:</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>):</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>---&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--&gt;</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.\\n.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.\\n.\\n.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count(w_i, +)  count(w_i, -)\n",
       "#bbmme                       1              0\n",
       "#segalakatakata              1              0\n",
       "(-:                          1              0\n",
       "(:                           1              5\n",
       "):                           4              4\n",
       "--->                         1              0\n",
       "-->                          2              0\n",
       "->                           1              0\n",
       ".\\n.                         0              1\n",
       ".\\n.\\n.                      1              0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(freqs, orient='index', columns=['count(w_i, +)', 'count(w_i, -)'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-velvet",
   "metadata": {},
   "source": [
    "**Task 4**\n",
    "\n",
    "We can calculate the equation 4.12 now:\n",
    "\n",
    "$P(w_i|c)=count(w_i, c)/\\Sigma_{w∈V} count(w, c)$\n",
    "\n",
    "The denominator $\\Sigma_{w∈V} count(w, c)$ is simply sum of each column.\n",
    "\n",
    "|$w_i$| count($w_i$, +) | count($w_i$, -) | P(w_i\\|+) | P(w_i\\|-) |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |\n",
    "|(-:|1|0|0.000037|0.000000|\n",
    "|(:|1|6|0.000037|0.000222|\n",
    "|):|6|6|0.000224|0.000222|\n",
    "|--->|1|0|0.000037|0.000000|\n",
    "|happi|161|18|0.005998|0.000666|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comic-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(w_i, +)</th>\n",
       "      <th>count(w_i, -)</th>\n",
       "      <th>P(w_i|+)</th>\n",
       "      <th>P(w_i|-)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#bbmme</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#segalakatakata</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-:</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(:</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>):</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚂</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚖</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚙</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>󾆖</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>󾌴</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14884 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count(w_i, +)  count(w_i, -)  P(w_i|+)  P(w_i|-)\n",
       "#bbmme                       1              0  0.000033  0.000000\n",
       "#segalakatakata              1              0  0.000033  0.000000\n",
       "(-:                          1              0  0.000033  0.000000\n",
       "(:                           1              5  0.000033  0.000176\n",
       "):                           4              4  0.000131  0.000141\n",
       "...                        ...            ...       ...       ...\n",
       "🚂                            1              0  0.000033  0.000000\n",
       "🚖                            0              1  0.000000  0.000035\n",
       "🚙                            0              1  0.000000  0.000035\n",
       "󾆖                            0              1  0.000000  0.000035\n",
       "󾌴                            1              0  0.000033  0.000000\n",
       "\n",
       "[14884 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE #\n",
    "# Calculate the sum of each column\n",
    "sum_positive = df['count(w_i, +)'].sum()\n",
    "sum_negative = df['count(w_i, -)'].sum()\n",
    "\n",
    "# Calculate the probabilities P(w_i|+) and P(w_i|-)\n",
    "df['P(w_i|+)'] = df['count(w_i, +)'] / sum_positive\n",
    "df['P(w_i|-)'] = df['count(w_i, -)'] / sum_negative\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-threshold",
   "metadata": {},
   "source": [
    "**Task 5**\n",
    "\n",
    "Apply Laplacian smoothing as described in equation 4.14\n",
    "\n",
    "$P(w_i|c)=[count(w_i, c)+1]/[\\Sigma_{w∈V} count(w, c)$+len(vocabulary)]\n",
    "\n",
    "|$w_i$| count($w_i$, +) | count($w_i$, -) | P(w_i\\|+) | P(w_i\\|-) |P(w_i\\|+) smooth | P(w_i\\|-) smooth |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |----------- |\n",
    "|(-:|1|0|0.000037|0.000000|0.000056|0.000028|\n",
    "|(:|1|6|0.000037|0.000222|0.000056|0.000194|\n",
    "|):|6|6|0.000224|0.000222|0.000195|0.000194|\n",
    "|--->|1|0|0.000037|0.000000|0.000056|0.000028|\n",
    "|happi|161|18|0.005998|0.000666|0.004509|0.000526|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comparative-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(w_i, +)</th>\n",
       "      <th>count(w_i, -)</th>\n",
       "      <th>P(w_i|+)</th>\n",
       "      <th>P(w_i|-)</th>\n",
       "      <th>P(w_i|+) smooth</th>\n",
       "      <th>P(w_i|-) smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#bbmme</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#segalakatakata</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-:</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(:</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>):</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚂</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚖</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚙</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>󾆖</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>󾌴</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14884 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count(w_i, +)  count(w_i, -)  P(w_i|+)  P(w_i|-)  \\\n",
       "#bbmme                       2              1  0.000033  0.000000   \n",
       "#segalakatakata              2              1  0.000033  0.000000   \n",
       "(-:                          2              1  0.000033  0.000000   \n",
       "(:                           2              6  0.000033  0.000176   \n",
       "):                           5              5  0.000131  0.000141   \n",
       "...                        ...            ...       ...       ...   \n",
       "🚂                            2              1  0.000033  0.000000   \n",
       "🚖                            1              2  0.000000  0.000035   \n",
       "🚙                            1              2  0.000000  0.000035   \n",
       "󾆖                            1              2  0.000000  0.000035   \n",
       "󾌴                            2              1  0.000033  0.000000   \n",
       "\n",
       "                 P(w_i|+) smooth  P(w_i|-) smooth  \n",
       "#bbmme                  0.000044         0.000023  \n",
       "#segalakatakata         0.000044         0.000023  \n",
       "(-:                     0.000044         0.000023  \n",
       "(:                      0.000044         0.000139  \n",
       "):                      0.000110         0.000115  \n",
       "...                          ...              ...  \n",
       "🚂                       0.000044         0.000023  \n",
       "🚖                       0.000022         0.000046  \n",
       "🚙                       0.000022         0.000046  \n",
       "󾆖                       0.000022         0.000046  \n",
       "󾌴                       0.000044         0.000023  \n",
       "\n",
       "[14884 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE #\n",
    "# Apply Laplacian smoothing\n",
    "smooth_factor = len(vocabulary)  # length of vocabulary\n",
    "\n",
    "# Add 1 to each count in the numerator\n",
    "df['count(w_i, +)'] += 1\n",
    "df['count(w_i, -)'] += 1\n",
    "\n",
    "# Add the Laplacian smoothing factor to the denominator\n",
    "denominator_smoothed_positive = sum_positive + smooth_factor\n",
    "denominator_smoothed_negative = sum_negative + smooth_factor\n",
    "\n",
    "# Recalculate the probabilities with Laplacian smoothing\n",
    "df['P(w_i|+) smooth'] = df['count(w_i, +)'] / denominator_smoothed_positive\n",
    "df['P(w_i|-) smooth'] = df['count(w_i, -)'] / denominator_smoothed_negative\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-target",
   "metadata": {},
   "source": [
    "**Task 6**\n",
    "\n",
    "The final piece of the puzzle is equation 4.11\n",
    "\n",
    "$P(c) = N_c/N_{doc}$\n",
    "\n",
    "$N_c$: the number of tweet in our training data with class c\n",
    "$N_{doc}$: the total number of tweets.\n",
    "\n",
    "P(+) = number of positive tweets / number of tweets\n",
    "\n",
    "P(-) = number of negative tweets / number of tweets\n",
    "\n",
    "Calculate P(+) and P(-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sufficient-bhutan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(+) = 0.5\n",
      "P(-) = 0.5\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE #\n",
    "# Calculate the number of positive and negative tweets\n",
    "num_positive_tweets = len(positive_tweets_tr)\n",
    "num_negative_tweets = len(negative_tweets_tr)\n",
    "\n",
    "# Calculate the total number of tweets\n",
    "total_tweets = num_positive_tweets + num_negative_tweets\n",
    "\n",
    "# Calculate P(+) and P(-)\n",
    "P_positive = num_positive_tweets / total_tweets\n",
    "P_negative = num_negative_tweets / total_tweets\n",
    "\n",
    "# Print the results\n",
    "print(\"P(+) =\", P_positive)\n",
    "print(\"P(-) =\", P_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-newton",
   "metadata": {},
   "source": [
    "**Task 7**\n",
    "\n",
    "Write the Naive Bayes algorithm by implementing equations 4.5/4.6\n",
    "\n",
    "Say we have a tweet with 2 tokens `['damnit', ':(']`. Probability of these tweet being positive is proportional to:\n",
    "\n",
    "`P(tweet|+)P(+)` = `P('damnit'|+) * P(':('|+) * P(+)`\n",
    "\n",
    "and negative is proportional to:\n",
    "\n",
    "`P(tweet|-)P(-)` = `P('damnit'|-) * P(':('|-) * P(-)`\n",
    "\n",
    "If `P(tweet|+)P(+)` > `P(tweet|-)P(-)`, tweet is positive and else negative.\n",
    "\n",
    "Predict whether this tweet is positive or negative using equations described above. Use the probabilities calculated using Laplacian smoothing.\n",
    "\n",
    "Remember, section 4.2 page 62\n",
    "\n",
    "> What do we do about words that occur in our test data but are not in our vocab- ulary at all because they did not occur in any training document in any class? The solution for such unknown words is to ignore them—remove them from the test document and not include any probability for them at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "greater-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@luketothestar', 'damnit', ':(']\n"
     ]
    }
   ],
   "source": [
    "tw = negative_tweets_te[3]\n",
    "print(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "private-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@luketothestar', 'damnit', ':(']\n"
     ]
    }
   ],
   "source": [
    "# Given tweet\n",
    "tw = negative_tweets_te[3]\n",
    "print(tw)\n",
    "\n",
    "# Initialize probabilities for positive and negative classes\n",
    "prob_pos = P_positive\n",
    "prob_neg = P_negative\n",
    "\n",
    "# Iterate over tokens in the tweet\n",
    "for token in tw:\n",
    "    # Check if the token is in the vocabulary\n",
    "    if token in df.index:\n",
    "        # Multiply the probabilities with P(token|+) and P(token|-)\n",
    "        prob_pos *= df.loc[token, 'P(w_i|+) smooth']\n",
    "        prob_neg *= df.loc[token, 'P(w_i|-) smooth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rough-clark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1993973651219566e-05, 0.0409207456515211)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pos, prob_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "existing-recommendation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class negative\n"
     ]
    }
   ],
   "source": [
    "if prob_pos > prob_neg:\n",
    "    print('Class positive')\n",
    "else:\n",
    "    print('Class negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-collect",
   "metadata": {},
   "source": [
    "**Task 8**\n",
    "\n",
    "As explained in section 4.1 page 61\n",
    "\n",
    "> Naive Bayes calculations, like calculations for language modeling, are done in log space, to avoid underflow and increase speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "appointed-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.332636185032189e-302\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Numerical underflow\n",
    "print(0.5**1000)\n",
    "print(0.5**10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-raise",
   "metadata": {},
   "source": [
    "Calcuate log likelihoods for P(w_i|+)\\_smooth and P(w_i|-)\\_smooth\n",
    "\n",
    "|$w_i$| count($w_i$, +) | count($w_i$, -) | P(w_i\\|+) | P(w_i\\|-) |P(w_i\\|+) smooth | P(w_i\\|-) smooth |log(P(w_i\\|+) smooth)|log(P(w_i\\|-) smooth)|\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |----------- |----------- |----------- |\n",
    "|(-:|1|0|0.000037|0.000000|0.000056|0.000028|-9.796125|-10.494519|\n",
    "|(:|1|6|0.000037|0.000222|0.000056|0.000194|-9.796125|-8.548609|\n",
    "|):|6|6|0.000224|0.000222|0.000195|0.000194|-8.543362|-8.548609|\n",
    "|--->|1|0|0.000037|0.000000|0.000056|0.000028|-9.796125|-10.494519|\n",
    "|happi|161|18|0.005998|0.000666|0.004509|0.000526|-5.401676|-7.550080|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "liberal-twenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(w_i, +)</th>\n",
       "      <th>count(w_i, -)</th>\n",
       "      <th>P(w_i|+)</th>\n",
       "      <th>P(w_i|-)</th>\n",
       "      <th>P(w_i|+) smooth</th>\n",
       "      <th>P(w_i|-) smooth</th>\n",
       "      <th>log(P(w_i|+) smooth)</th>\n",
       "      <th>log(P(w_i|-) smooth)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#bbmme</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-10.031595</td>\n",
       "      <td>-10.675700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#segalakatakata</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-10.031595</td>\n",
       "      <td>-10.675700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-:</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-10.031595</td>\n",
       "      <td>-10.675700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(:</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-10.031595</td>\n",
       "      <td>-8.883941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>):</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-9.115304</td>\n",
       "      <td>-9.066262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚂</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-10.031595</td>\n",
       "      <td>-10.675700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚖</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-10.724742</td>\n",
       "      <td>-9.982553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚙</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-10.724742</td>\n",
       "      <td>-9.982553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>󾆖</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-10.724742</td>\n",
       "      <td>-9.982553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>󾌴</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-10.031595</td>\n",
       "      <td>-10.675700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14884 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count(w_i, +)  count(w_i, -)  P(w_i|+)  P(w_i|-)  \\\n",
       "#bbmme                       2              1  0.000033  0.000000   \n",
       "#segalakatakata              2              1  0.000033  0.000000   \n",
       "(-:                          2              1  0.000033  0.000000   \n",
       "(:                           2              6  0.000033  0.000176   \n",
       "):                           5              5  0.000131  0.000141   \n",
       "...                        ...            ...       ...       ...   \n",
       "🚂                            2              1  0.000033  0.000000   \n",
       "🚖                            1              2  0.000000  0.000035   \n",
       "🚙                            1              2  0.000000  0.000035   \n",
       "󾆖                            1              2  0.000000  0.000035   \n",
       "󾌴                            2              1  0.000033  0.000000   \n",
       "\n",
       "                 P(w_i|+) smooth  P(w_i|-) smooth  log(P(w_i|+) smooth)  \\\n",
       "#bbmme                  0.000044         0.000023            -10.031595   \n",
       "#segalakatakata         0.000044         0.000023            -10.031595   \n",
       "(-:                     0.000044         0.000023            -10.031595   \n",
       "(:                      0.000044         0.000139            -10.031595   \n",
       "):                      0.000110         0.000115             -9.115304   \n",
       "...                          ...              ...                   ...   \n",
       "🚂                       0.000044         0.000023            -10.031595   \n",
       "🚖                       0.000022         0.000046            -10.724742   \n",
       "🚙                       0.000022         0.000046            -10.724742   \n",
       "󾆖                       0.000022         0.000046            -10.724742   \n",
       "󾌴                       0.000044         0.000023            -10.031595   \n",
       "\n",
       "                 log(P(w_i|-) smooth)  \n",
       "#bbmme                     -10.675700  \n",
       "#segalakatakata            -10.675700  \n",
       "(-:                        -10.675700  \n",
       "(:                          -8.883941  \n",
       "):                          -9.066262  \n",
       "...                               ...  \n",
       "🚂                          -10.675700  \n",
       "🚖                           -9.982553  \n",
       "🚙                           -9.982553  \n",
       "󾆖                           -9.982553  \n",
       "󾌴                          -10.675700  \n",
       "\n",
       "[14884 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE \n",
    "import math\n",
    "# Calculate log likelihoods for P(w_i|+)_smooth and P(w_i|-)_smooth\n",
    "df['log(P(w_i|+) smooth)'] = df['P(w_i|+) smooth'].apply(lambda x: math.log(x))\n",
    "df['log(P(w_i|-) smooth)'] = df['P(w_i|-) smooth'].apply(lambda x: math.log(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-pension",
   "metadata": {},
   "source": [
    "**Task 9**\n",
    "\n",
    "Repeat Task 7 but this time using log likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "tropical-diabetes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@luketothestar', 'damnit', ':(']\n"
     ]
    }
   ],
   "source": [
    "tw = negative_tweets_te[3]\n",
    "print(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "civilian-float",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@luketothestar', 'damnit', ':(']\n",
      "Log likelihood for positive class: -10.724742067074814\n",
      "Log likelihood for negative class: -3.196118115886798\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE #\n",
    "# Given tweet\n",
    "tw = negative_tweets_te[3]\n",
    "print(tw)\n",
    "\n",
    "# Initialize log likelihoods for positive and negative classes\n",
    "log_prob_pos = math.log(P_positive)\n",
    "log_prob_neg = math.log(P_negative)\n",
    "\n",
    "# Iterate over tokens in the tweet\n",
    "for token in tw:\n",
    "    # Check if the token is in the vocabulary\n",
    "    if token in df.index:\n",
    "        # Add the log likelihoods of the token being in each class\n",
    "        log_prob_pos += df.loc[token, 'log(P(w_i|+) smooth)']\n",
    "        log_prob_neg += df.loc[token, 'log(P(w_i|-) smooth)']\n",
    "\n",
    "# Print the log likelihoods\n",
    "print(\"Log likelihood for positive class:\", log_prob_pos)\n",
    "print(\"Log likelihood for negative class:\", log_prob_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "phantom-weekend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10.724742067074814, -3.196118115886798)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_pos, log_prob_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "innocent-prison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.199397365121956e-05, 0.0409207456515211)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(log_prob_pos), np.exp(log_prob_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pacific-victim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1993973651219566e-05, 0.0409207456515211)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pos, prob_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "occasional-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class negative\n"
     ]
    }
   ],
   "source": [
    "if log_prob_pos > log_prob_neg:\n",
    "    print('Class positive')\n",
    "else:\n",
    "    print('Class negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-ceiling",
   "metadata": {},
   "source": [
    "**Task 10**\n",
    "\n",
    "Putting everything together, predict whether a tweet is positive or negative, for each tweet in the test set. Calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "overall-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_preds = []\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "# Iterate over each tweet in the test set\n",
    "for tweet in positive_tweets_te + negative_tweets_te:\n",
    "    # Initialize log likelihoods for positive and negative classes\n",
    "    log_prob_pos = math.log(P_positive)\n",
    "    log_prob_neg = math.log(P_negative)\n",
    "    \n",
    "    # Iterate over tokens in the tweet\n",
    "    for token in tweet:\n",
    "        # Check if the token is in the vocabulary\n",
    "        if token in df.index:\n",
    "            # Add the log likelihoods of the token being in each class\n",
    "            log_prob_pos += df.loc[token, 'log(P(w_i|+) smooth)']\n",
    "            log_prob_neg += df.loc[token, 'log(P(w_i|-) smooth)']\n",
    "    \n",
    "    # Predict the sentiment based on which log likelihood is higher\n",
    "    if log_prob_pos > log_prob_neg:\n",
    "        y_preds.append(1)  # positive\n",
    "    else:\n",
    "        y_preds.append(0)  # negative\n",
    "    \n",
    "    # Determine true label based on tweet's origin\n",
    "    if tweet in positive_tweets_te:\n",
    "        y_test.append(1)  # positive\n",
    "    else:\n",
    "        y_test.append(0)  # negative\n",
    "    \n",
    "y_preds = np.array(y_preds)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "english-marine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_preds == y_test)/len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
