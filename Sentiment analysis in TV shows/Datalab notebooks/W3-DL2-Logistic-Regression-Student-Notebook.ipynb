{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seven-russia",
   "metadata": {},
   "source": [
    "In the last DataLab you implemented a Naive Bayes classifier. You created a frequency table. In this DataLab you will use this table to create features for a logistic regression algorithm, and use scikit-learn to build the model.\n",
    "\n",
    "**Chapter 5 of the book \"Speech and Language Processing\" is referenced in this notebook.**\n",
    "\n",
    "First, repeat the steps you did in the last DataLab until and including Task 3. In other words create this table again:\n",
    "\n",
    "|$w_i$| count($w_i$, +) | count($w_i$, -) |\n",
    "| ----------- | ----------- |----------- |\n",
    "|(-:|1|0|\n",
    "|(:|1|6|\n",
    "|):|6|6|\n",
    "|--->|1|0|\n",
    "|happi|161|18|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acknowledged-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import re                                  \n",
    "import string  \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "common-proposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\neilr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bottom-contract",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\neilr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "naval-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "historic-description",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets:  5000\n",
      "Number of negative tweets:  5000\n",
      "\n",
      "The type of all_positive_tweets is:  <class 'list'>\n",
      "The type of a tweet entry is:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive tweets: ', len(all_positive_tweets))\n",
    "print('Number of negative tweets: ', len(all_negative_tweets))\n",
    "\n",
    "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
    "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "undefined-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m@tmhcuddly I'm so excited, we should definitely meet up :)\n",
      "\u001b[91mI'm coughing. :(\n"
     ]
    }
   ],
   "source": [
    "# print positive in greeen\n",
    "print('\\033[92m' + all_positive_tweets[random.randint(0,5000)])\n",
    "\n",
    "# print negative in red\n",
    "print('\\033[91m' + all_negative_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-dealer",
   "metadata": {},
   "source": [
    "## 1) Tweet preprocessing\n",
    "\n",
    "Again, use the function `tweet_processor()` you created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "proper-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        processed_tweet: a list of token\n",
    "        \n",
    "    Processing steps:\n",
    "    - Removes hyperlinks\n",
    "    - Removes # sign\n",
    "    - Tokenizes\n",
    "    - Removes stopwords and punctuation\n",
    "    - Stem tokens\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "    # Remove URLs using regular expression\n",
    "    processed_tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    processed_tweet = re.sub(r'#([^\\s]+)', r'\\1', processed_tweet)\n",
    "    \n",
    "    # Tokenize the tweet using TweetTokenizer\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=False)\n",
    "    processed_tweet = tokenizer.tokenize(processed_tweet)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stopwords_english = set(stopwords.words('english'))\n",
    "    processed_tweet = [word for word in processed_tweet if word not in stopwords_english]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    processed_tweet = [word for word in processed_tweet if word not in string.punctuation]\n",
    "    \n",
    "    # Stem the tokens\n",
    "    stemmer = PorterStemmer()\n",
    "    processed_tweet = [stemmer.stem(word) for word in processed_tweet]\n",
    "\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-mounting",
   "metadata": {},
   "source": [
    "And sanity check if it works.\n",
    "    \n",
    "Example tweet:\n",
    "    \n",
    "`My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i`\n",
    "\n",
    "Expected output:\n",
    "\n",
    "`['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '…']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "assisted-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i\n"
     ]
    }
   ],
   "source": [
    "example_tweet = ('My beautiful sunflowers on a sunny Friday morning off :)'\n",
    "                 ' #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i')\n",
    "print(example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "olive-residence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beauti',\n",
       " 'sunflow',\n",
       " 'sunni',\n",
       " 'friday',\n",
       " 'morn',\n",
       " ':)',\n",
       " 'sunflow',\n",
       " 'favourit',\n",
       " 'happi',\n",
       " 'friday',\n",
       " '…']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_processor(example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-remove",
   "metadata": {},
   "source": [
    "Before going any further, let's split the dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "compound-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% training 20% testing\n",
    "positive_tweets_tr = all_positive_tweets[:4000]\n",
    "positive_tweets_te = all_positive_tweets[4000:]\n",
    "\n",
    "negative_tweets_tr = all_negative_tweets[:4000]\n",
    "negative_tweets_te = all_negative_tweets[4000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-heating",
   "metadata": {},
   "source": [
    "**Task 1 (From the last DataLab)**\n",
    "\n",
    "The function `tweet_processor()` expects a single tweet to process. But you have lists of tweets to process. Write a function called `tweet_processor_list()` that accept a list of strings (tweets) and returns a list of processed tweets. A processed tweet is a list of tokens. Therefore  `tweet_processor_list()` should return a list of lists.\n",
    "\n",
    "The first two items in the `positive_tweets_tr` are:\n",
    "\n",
    "```\n",
    "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
    " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!']\n",
    " ```\n",
    " \n",
    " the expected output of `tweet_processor_list()` is:\n",
    " \n",
    " ```\n",
    " [['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)'],\n",
    " ['hey',\n",
    "  'jame',\n",
    "  'odd',\n",
    "  ':/',\n",
    "  'pleas',\n",
    "  'call',\n",
    "  'contact',\n",
    "  'centr',\n",
    "  '02392441234',\n",
    "  'abl',\n",
    "  'assist',\n",
    "  ':)',\n",
    "  'mani',\n",
    "  'thank']]\n",
    " \n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "virgin-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processor_list(tweet_list):\n",
    "    # YOUR CODE HERE #\n",
    "    processed_tweet_list = []\n",
    "    for tweet in tweet_list:\n",
    "        processed_tweet = tweet_processor(tweet)\n",
    "        processed_tweet_list.append(processed_tweet)\n",
    "    return processed_tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "emerging-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets_tr = tweet_processor_list(positive_tweets_tr)\n",
    "positive_tweets_te = tweet_processor_list(positive_tweets_te)\n",
    "\n",
    "negative_tweets_tr = tweet_processor_list(negative_tweets_tr)\n",
    "negative_tweets_te = tweet_processor_list(negative_tweets_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-biodiversity",
   "metadata": {},
   "source": [
    "**Task 2  (From the last DataLab)**\n",
    "\n",
    "Now it is time to creative the _vocabulary_ as defined in Chapter 4, Section 4.2:\n",
    "\n",
    "> vocabulary V consists of the union of all the word types in all classes\n",
    "\n",
    "Combine all the tokens in `positive_tweets_tr` and `negative_tweets_tr` into one big list and get the unique tokens from this list.\n",
    "\n",
    "Expected length of the vocabulary is `9085` unique tokens. Notice that if you use a different train/test split or different preprocessing this number will be different.\n",
    "\n",
    "First 50 tokens in the vocabulary:\n",
    "\n",
    "```\n",
    "['(-:',\n",
    " '(:',\n",
    " '):',\n",
    " '--->',\n",
    " '-->',\n",
    " '->',\n",
    " '.\\n.',\n",
    " '.\\n.\\n.',\n",
    " '. .',\n",
    " '. . .',\n",
    " '. ..',\n",
    " '. ...',\n",
    " '..',\n",
    " '...',\n",
    " '0',\n",
    " '0-100',\n",
    " '0-2',\n",
    " '0.001',\n",
    " '0.7',\n",
    " '00',\n",
    " '00128835',\n",
    " '009',\n",
    " '00962778381',\n",
    " '01282',\n",
    " '01482',\n",
    " '01:15',\n",
    " '01:16',\n",
    " '02079',\n",
    " '02392441234',\n",
    " '0272 3306',\n",
    " '0330 333 7234',\n",
    " '0345',\n",
    " '05.15',\n",
    " '07:02',\n",
    " '07:17',\n",
    " '07:24',\n",
    " '07:25',\n",
    " '07:32',\n",
    " '07:34',\n",
    " '08',\n",
    " '0878 0388',\n",
    " '08962464174',\n",
    " '0ne',\n",
    " '1',\n",
    " '1,300',\n",
    " '1,500',\n",
    " '1-0',\n",
    " '1.300',\n",
    " '1.8',\n",
    " '1/2']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eligible-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary: 14884\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE #\n",
    "# Combine all tokens from positive_tweets_tr and negative_tweets_tr\n",
    "all_tweets = positive_tweets_tr + negative_tweets_tr\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "all_tokens = [token for tweet in all_tweets for token in tweet]\n",
    "\n",
    "# Get unique tokens\n",
    "vocabulary = list(set(all_tokens))\n",
    "\n",
    "# Sort the vocabulary for consistency\n",
    "vocabulary.sort()\n",
    "\n",
    "# Flatten the list of lists\n",
    "flattened_positive_tweets = [token for sublist in positive_tweets_tr for token in sublist]\n",
    "flattened_negative_tweets = [token for sublist in negative_tweets_tr for token in sublist]\n",
    "\n",
    "# Print the first 50 tokens in the vocabulary\n",
    "#print(vocabulary[:50])\n",
    "\n",
    "# Print the length of the vocabulary\n",
    "print(\"Length of vocabulary:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-destination",
   "metadata": {},
   "source": [
    "**Task 3  (From the last DataLab)**\n",
    "\n",
    "In order to calculate the equation 4.12\n",
    "\n",
    "$P(w_i|c)=count(w_i, c)/\\Sigma_{w∈V} count(w, c)$\n",
    "\n",
    "We first need to calculate $count(w_i, c)$ which is the number of times each token in the vocabulary occurs in class c. This is also called the word frequency table.\n",
    "\n",
    "|$w_i$| count($w_i$, +) | count($w_i$, -) |\n",
    "| ----------- | ----------- |----------- |\n",
    "|(-:|1|0|\n",
    "|(:|1|6|\n",
    "|):|6|6|\n",
    "|--->|1|0|\n",
    "|happi|161|18|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "level-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_count_pos = Counter(flattened_positive_tweets)\n",
    "word_count_neg = Counter(flattened_negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adjacent-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the frequency table\n",
    "freqs = {}\n",
    "\n",
    "# Iterate over the vocabulary\n",
    "for token in vocabulary:\n",
    "    # Get the count of the token in positive class (default to 0 if not found)\n",
    "    count_pos = word_count_pos.get(token, 0)\n",
    "    # Get the count of the token in negative class (default to 0 if not found)\n",
    "    count_neg = word_count_neg.get(token, 0)\n",
    "    # Store the counts in the dictionary\n",
    "    freqs[token] = (count_pos, count_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "raised-tuesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(w_i, +)</th>\n",
       "      <th>count(w_i, -)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#bbmme</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#segalakatakata</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-:</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(:</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>):</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>---&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--&gt;</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.\\n.</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.\\n.\\n.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count(w_i, +)  count(w_i, -)\n",
       "#bbmme                       2              0\n",
       "#segalakatakata              1              0\n",
       "(-:                          1              0\n",
       "(:                           1              6\n",
       "):                           6              6\n",
       "--->                         1              0\n",
       "-->                          2              0\n",
       "->                           1              0\n",
       ".\\n.                         0              2\n",
       ".\\n.\\n.                      1              0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(freqs, orient='index', columns=['count(w_i, +)', 'count(w_i, -)'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-fountain",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Now it is time to create features for a logistic regression model. How can we create features from the following table?\n",
    "\n",
    "|$w_i$| count($w_i$, +) | count($w_i$, -) |\n",
    "| ----------- | ----------- |----------- |\n",
    "|(-:|1|0|\n",
    "|(:|1|6|\n",
    "|):|6|6|\n",
    "|--->|1|0|\n",
    "|happi|161|18|\n",
    "\n",
    "Let's create two features, one for the positive counts and one for the negative counts.\n",
    "\n",
    "- For each token in the tweet get count($w_i$, +) from the table\n",
    "- Calculate the sum\n",
    "- This will be your first feature ($x_1$)\n",
    "\n",
    "Similarly\n",
    "\n",
    "- For each token in the tweet get count($w_i$, -) from the table\n",
    "- Calculate the sum\n",
    "- This will be your second feature ($x_2$)\n",
    "\n",
    "Finally, repeat this for every tweet in the training and test sets. Let's get back to our example tweet to better understand what you need to do.\n",
    "\n",
    "Example tweet (raw):\n",
    "    \n",
    "`My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i`\n",
    "\n",
    "Example tweet (processed):\n",
    "\n",
    "`['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '…']`\n",
    "\n",
    "|tokens|count(w_i, +)|count(w_i, -)|\n",
    "|--|--|--|\n",
    "|beauti|45|10|\n",
    "|sunflow|2|0|\n",
    "|sunni|5|1|\n",
    "|friday|91|9|\n",
    "|morn|68|23|\n",
    "|:)|2847|2|\n",
    "|sunflow|2|0|\n",
    "|favourit|9|8|\n",
    "|happi|161|18|\n",
    "|friday|91|9|\n",
    "|…|31|14|\n",
    "|Total|$x_1$ = 3352|$x_2$ = 94|\n",
    "\n",
    "Sanity check your array shapes. Expected outputs:\n",
    "\n",
    "|Array|Shape|\n",
    "|--|--|\n",
    "|X_train|(8000, 2)|\n",
    "|y_train|(8000,)|\n",
    "|X_test|(2000, 2)|\n",
    "|y_test|(2000,)|\n",
    "\n",
    "\n",
    "X_train output:\n",
    "\n",
    "```\n",
    "array([[2847,    2],\n",
    "       [ 504,   94],\n",
    "       [   2,    1],\n",
    "       ...,\n",
    "       [   0,  378],\n",
    "       [   1, 3663],\n",
    "       [   1, 3663]])\n",
    "```\n",
    "\n",
    "**Task 1 (First task of this DataLab)**\n",
    "\n",
    "Create $x_1$ and $x_2$ as described above, for each tweet in the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "vietnamese-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels to the training set (1 for positive, 0 for negative)\n",
    "y_train = np.concatenate((np.ones(len(positive_tweets_tr)), np.zeros(len(negative_tweets_tr))))\n",
    "\n",
    "# Assign labels to the test set (1 for positive, 0 for negative)\n",
    "y_test = np.concatenate((np.ones(len(positive_tweets_te)), np.zeros(len(negative_tweets_te))))\n",
    "\n",
    "# Initialize empty lists to store features for training and test sets\n",
    "X1_train = []\n",
    "X2_train = []\n",
    "X1_test = []\n",
    "X2_test = []\n",
    "\n",
    "# Function to calculate features for a single tweet\n",
    "def calculate_features(tweet):\n",
    "    # Initialize counters for positive and negative counts\n",
    "    count_pos = 0\n",
    "    count_neg = 0\n",
    "    \n",
    "    # Iterate over tokens in the tweet\n",
    "    for token in tweet:\n",
    "        # Get the counts for the token from the frequency table\n",
    "        count_wi_pos, count_wi_neg = freqs.get(token, (0, 0))\n",
    "        # Increment the counters\n",
    "        count_pos += count_wi_pos\n",
    "        count_neg += count_wi_neg\n",
    "    \n",
    "    return count_pos, count_neg\n",
    "\n",
    "# Calculate features for each tweet in the training set\n",
    "for tweet in positive_tweets_tr:\n",
    "    count_pos, count_neg = calculate_features(tweet)\n",
    "    X1_train.append(count_pos)\n",
    "    X2_train.append(count_neg)\n",
    "\n",
    "for tweet in negative_tweets_tr:\n",
    "    count_pos, count_neg = calculate_features(tweet)\n",
    "    X1_train.append(count_pos)\n",
    "    X2_train.append(count_neg)\n",
    "\n",
    "# Calculate features for each tweet in the test set\n",
    "for tweet in positive_tweets_te:\n",
    "    count_pos, count_neg = calculate_features(tweet)\n",
    "    X1_test.append(count_pos)\n",
    "    X2_test.append(count_neg)\n",
    "\n",
    "for tweet in negative_tweets_te:\n",
    "    count_pos, count_neg = calculate_features(tweet)\n",
    "    X1_test.append(count_pos)\n",
    "    X2_test.append(count_neg)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X1_train = np.array(X1_train).reshape(-1, 1)\n",
    "X2_train = np.array(X2_train).reshape(-1, 1)\n",
    "X1_test = np.array(X1_test).reshape(-1, 1)\n",
    "X2_test = np.array(X2_test).reshape(-1, 1)\n",
    "\n",
    "# Concatenate X1_train and X2_train to get X_train\n",
    "X_train = np.concatenate((X1_train, X2_train), axis=1)\n",
    "\n",
    "# Concatenate X1_test and X2_test to get X_test\n",
    "X_test = np.concatenate((X1_test, X2_test), axis=1)\n",
    "\n",
    "# Concatenate features with labels for training set\n",
    "train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Concatenate features with labels for test set\n",
    "test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Splitting features and labels\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "given-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 2), (8000,), (2000, 2), (2000,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-sauce",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Now you are ready to build a logistic regression model using scikit-learn.\n",
    "\n",
    "Try with and without normalization (as described in section 5.2 page 83 of the book Speech and Language Processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "handy-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without normalization: 0.994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the test data\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy without normalization:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3379a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with normalization: 0.994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logistic_model_normalized = LogisticRegression()\n",
    "\n",
    "# Fit the model to the normalized training data\n",
    "logistic_model_normalized.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Predict labels for the normalized test data\n",
    "y_pred_normalized = logistic_model_normalized.predict(X_test_normalized)\n",
    "\n",
    "# Calculate accuracy score for normalized data\n",
    "accuracy_normalized = accuracy_score(y_test, y_pred_normalized)\n",
    "print(\"Accuracy with normalization:\", accuracy_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-stick",
   "metadata": {},
   "source": [
    "Compare the two models you have developed (Naive Bayes and Logistic Regression) considering _5.2.4 Choosing a classifier_ on page 85 of the book Speech and Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-invitation",
   "metadata": {},
   "source": [
    "**Task 3**\n",
    "\n",
    "Designing new features (discussed in page 83 of the book Speech and Language Processing) is an important part of building models. You created two features in Task 1. Now, design your own features and try to improve the model performance. Check the table on page 82 for inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-adelaide",
   "metadata": {},
   "source": [
    "**Task 4**\n",
    "\n",
    "Use the `SentimentIntensityAnalyzer` from `nltk` to predict the sentiment of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-microwave",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\neilr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-combine",
   "metadata": {},
   "source": [
    "It tells you if a tweet (or a text in general) is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"The acting was good.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-crest",
   "metadata": {},
   "source": [
    "Notice that a tweet can contain both sentiments at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-charge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.347, 'neu': 0.511, 'pos': 0.142, 'compound': -0.5859}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"The acting was good, but the story was bad.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-award",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.172, 'neu': 0.534, 'pos': 0.294, 'compound': 0.3818}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"The acting was bad, but the story was good.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-majority",
   "metadata": {},
   "source": [
    "Use the `compound` score to decide whether a tweet is positive or negative. If the compound is a positive number, the prediction is positive. If it is a negative number the prediction is negative.\n",
    "\n",
    "If the `compound` is zero it is neither positive, nor negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-negotiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"I feel neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-highlight",
   "metadata": {},
   "source": [
    "Now calculate the accuracy of `SentimentIntensityAnalyzer` on the **raw** test tweets. Decide how you would like to handle neutral tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% training 20% testing\n",
    "positive_tweets_tr_raw = all_positive_tweets[:4000]\n",
    "positive_tweets_te_raw = all_positive_tweets[4000:]\n",
    "\n",
    "negative_tweets_tr_raw = all_negative_tweets[:4000]\n",
    "negative_tweets_te_raw = all_negative_tweets[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "small-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SentimentIntensityAnalyzer on raw test tweets: 0.8786588610963278\n"
     ]
    }
   ],
   "source": [
    "# Function to predict sentiment of a tweet using compound score\n",
    "def predict_sentiment(tweet):\n",
    "    # Get polarity scores\n",
    "    scores = sia.polarity_scores(tweet)\n",
    "    compound_score = scores['compound']\n",
    "    \n",
    "    # Decide sentiment based on compound score\n",
    "    if compound_score > 0:\n",
    "        return 1  # Positive sentiment\n",
    "    elif compound_score < 0:\n",
    "        return 0  # Negative sentiment\n",
    "    else:\n",
    "        return np.nan  # Neutral sentiment\n",
    "\n",
    "# Function to calculate accuracy of SentimentIntensityAnalyzer on test tweets\n",
    "def calculate_accuracy(test_tweets_raw):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for tweet in test_tweets_raw:\n",
    "        # Predict sentiment of the tweet\n",
    "        prediction = predict_sentiment(tweet)\n",
    "        \n",
    "        # Increment counters\n",
    "        if not np.isnan(prediction):  # Ignore neutral predictions\n",
    "            if prediction == 1 and tweet in positive_tweets_te_raw:\n",
    "                correct_predictions += 1\n",
    "            elif prediction == 0 and tweet in negative_tweets_te_raw:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy on raw test tweets\n",
    "accuracy_sia = calculate_accuracy(positive_tweets_te_raw + negative_tweets_te_raw)\n",
    "print(\"Accuracy of SentimentIntensityAnalyzer on raw test tweets:\", accuracy_sia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-mechanism",
   "metadata": {},
   "source": [
    "**Task 5**\n",
    "\n",
    "Use the results of `SentimentIntensityAnalyzer` as new features to your Logistic Regression model. Try with and without normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "amino-victory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression with Sentiment Features (without normalization): 0.9962746141564662\n",
      "Accuracy of Logistic Regression with Sentiment Features (with normalization): 0.9941458222458754\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate sentiment features for a list of tweets\n",
    "def calculate_sentiment_features(tweet_list):\n",
    "    sentiment_features = []\n",
    "    for tweet in tweet_list:\n",
    "        prediction = predict_sentiment(tweet)\n",
    "        sentiment_features.append(prediction)\n",
    "    return sentiment_features\n",
    "\n",
    "# Calculate sentiment features for training and test sets\n",
    "sentiment_features_train = calculate_sentiment_features(positive_tweets_tr_raw + negative_tweets_tr_raw)\n",
    "sentiment_features_test = calculate_sentiment_features(positive_tweets_te_raw + negative_tweets_te_raw)\n",
    "\n",
    "# Reshape sentiment features arrays to match the shape of other features\n",
    "sentiment_features_train = np.array(sentiment_features_train).reshape(-1, 1)\n",
    "sentiment_features_test = np.array(sentiment_features_test).reshape(-1, 1)\n",
    "\n",
    "# Concatenate sentiment features with existing features for training and test sets\n",
    "X_train_with_sentiment = np.concatenate((X_train, sentiment_features_train), axis=1)\n",
    "X_test_with_sentiment = np.concatenate((X_test, sentiment_features_test), axis=1)\n",
    "\n",
    "# Remove tweets with NaN sentiment values from the training data\n",
    "nan_indices_train = np.isnan(sentiment_features_train).reshape(-1)\n",
    "X_train_with_sentiment = X_train_with_sentiment[~nan_indices_train]\n",
    "y_train = y_train[~nan_indices_train]\n",
    "\n",
    "# Remove tweets with NaN sentiment values from the test data\n",
    "nan_indices_test = np.isnan(sentiment_features_test).reshape(-1)\n",
    "X_test_with_sentiment = X_test_with_sentiment[~nan_indices_test]\n",
    "y_test = y_test[~nan_indices_test]\n",
    "\n",
    "# Train Logistic Regression model without normalization\n",
    "logistic_model_with_sentiment = LogisticRegression()\n",
    "logistic_model_with_sentiment.fit(X_train_with_sentiment, y_train)\n",
    "y_pred_with_sentiment = logistic_model_with_sentiment.predict(X_test_with_sentiment)\n",
    "accuracy_with_sentiment = accuracy_score(y_test, y_pred_with_sentiment)\n",
    "print(\"Accuracy of Logistic Regression with Sentiment Features (without normalization):\", accuracy_with_sentiment)\n",
    "\n",
    "# Normalize the features including sentiment features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_with_sentiment_normalized = scaler.fit_transform(X_train_with_sentiment)\n",
    "X_test_with_sentiment_normalized = scaler.transform(X_test_with_sentiment)\n",
    "\n",
    "# Train Logistic Regression model with normalized features including sentiment features\n",
    "logistic_model_with_sentiment_normalized = LogisticRegression()\n",
    "logistic_model_with_sentiment_normalized.fit(X_train_with_sentiment_normalized, y_train)\n",
    "y_pred_with_sentiment_normalized = logistic_model_with_sentiment_normalized.predict(X_test_with_sentiment_normalized)\n",
    "accuracy_with_sentiment_normalized = accuracy_score(y_test, y_pred_with_sentiment_normalized)\n",
    "print(\"Accuracy of Logistic Regression with Sentiment Features (with normalization):\", accuracy_with_sentiment_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
