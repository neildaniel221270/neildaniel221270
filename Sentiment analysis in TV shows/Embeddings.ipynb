{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\neilr\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickle file\n",
    "features = pd.read_pickle('./Datasets/feature_extraction_full.pkl')\n",
    "\n",
    "# Filter out rows where the emotion is \"neutral\"\n",
    "filtered_features = features[features['emotion'] != 'neutral']\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Word2Vec model\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('C:/Users/neilr/Documents/BUAS year 2/Block C/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(filtered_features['sentence'])\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "# Convert the tokenized sentences to sequences\n",
    "sequences = tokenizer.texts_to_sequences(filtered_features['sentence'])\n",
    "\n",
    "# Pad the sequences\n",
    "padded_sequences = pad_sequences(sequences, padding='post', maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_sequences\n",
    "y = filtered_features['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map words to their corresponding word vectors\n",
    "embedding_matrix = np.zeros((vocab_size + 1, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec_model:\n",
    "        embedding_matrix[i] = word2vec_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\neilr\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 300)           30327000  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1152128   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31479902 (120.09 MB)\n",
      "Trainable params: 1152902 (4.40 MB)\n",
      "Non-trainable params: 30327000 (115.69 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train_encoded))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size + 1, output_dim=300, input_length=30, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\neilr\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'],  run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8837/8837 [==============================] - 236s 27ms/step - loss: 0.1362 - accuracy: 0.9516 - val_loss: 0.7545 - val_accuracy: 0.8115\n",
      "Epoch 2/10\n",
      "8837/8837 [==============================] - 270s 31ms/step - loss: 0.1055 - accuracy: 0.9623 - val_loss: 0.8721 - val_accuracy: 0.8122\n",
      "Epoch 3/10\n",
      "8837/8837 [==============================] - 187s 21ms/step - loss: 0.0884 - accuracy: 0.9693 - val_loss: 0.9501 - val_accuracy: 0.8099\n",
      "Epoch 4/10\n",
      "8837/8837 [==============================] - 193s 22ms/step - loss: 0.0748 - accuracy: 0.9739 - val_loss: 1.0425 - val_accuracy: 0.8103\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "y_train_encoded_onehot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "history = model.fit(X_train, y_train_encoded_onehot, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2762/2762 [==============================] - 7s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the testing set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2762/2762 [==============================] - 18s 6ms/step - loss: 1.0387 - accuracy: 0.8111\n",
      "Test accuracy: 0.8111016750335693\n"
     ]
    }
   ],
   "source": [
    "# Convert target labels to one-hot encoding\n",
    "y_test_encoded_onehot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
    "\n",
    "# Evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_encoded_onehot)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predict it on the kaggle test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Girls are happy when they get flowers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>His jaw dropped in disbelief when he saw the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sometimes the ugly stench makes me wanna throw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The foul odor from the garbage bin was disgust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I can’t believe it, they lost the game in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence\n",
       "0   0              Girls are happy when they get flowers\n",
       "1   1  His jaw dropped in disbelief when he saw the p...\n",
       "2   2  Sometimes the ugly stench makes me wanna throw...\n",
       "3   3  The foul odor from the garbage bin was disgust...\n",
       "4   4  I can’t believe it, they lost the game in the ..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading kaggle test file\n",
    "file_path = \"C:/Users/neilr/Documents/BUAS year 2/Block C/2023-24c-fai2-adsai-neildaniel221270/Kaggle/Datasets multiclass/test (kaggle).csv\"\n",
    "test_kaggle = pd.read_csv(file_path, sep='\\t')\n",
    "test_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data\n",
    "X_test_kaggle = test_kaggle['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data from Kaggle test set\n",
    "sequences_kaggle = tokenizer.texts_to_sequences(X_test_kaggle)\n",
    "padded_sequences_kaggle = pad_sequences(sequences_kaggle, padding='post', maxlen=30)\n",
    "\n",
    "# Predict emotions on Kaggle test set\n",
    "y_pred_kaggle = model.predict(padded_sequences_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1862409e-04, 4.1155081e-06, 1.9114469e-04, 9.7730941e-01,\n",
       "        1.8328106e-05, 2.2258334e-02],\n",
       "       [1.2005935e-08, 9.7923156e-11, 1.7694929e-05, 1.4838902e-04,\n",
       "        1.3997644e-03, 9.9843413e-01],\n",
       "       [9.7705859e-01, 5.1050254e-05, 4.5764165e-07, 1.5528039e-10,\n",
       "        2.2887509e-02, 2.4075566e-06],\n",
       "       ...,\n",
       "       [1.7402707e-02, 8.6030877e-06, 2.2064932e-04, 9.8221934e-01,\n",
       "        2.1838543e-06, 1.4650705e-04],\n",
       "       [1.2159633e-02, 4.8530779e-05, 9.7986650e-01, 7.5915601e-04,\n",
       "        5.5714227e-06, 7.1605509e-03],\n",
       "       [1.2240220e-06, 5.4748898e-07, 1.2485098e-08, 9.9999285e-01,\n",
       "        2.3698701e-06, 3.0843416e-06]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert predicted probabilities to emotions\n",
    "def get_emotion(pred):\n",
    "    emotions = ['happiness', 'surprise', 'sadness', 'anger', 'fear', 'disgust', 'neutral']\n",
    "    return emotions[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predicted probabilities to emotions for Kaggle test set\n",
    "predicted_emotions = [get_emotion(pred) for pred in y_pred_kaggle]\n",
    "\n",
    "# Create a DataFrame for submission\n",
    "submission_df = pd.DataFrame({'id': test_kaggle['id'], 'emotion': predicted_emotions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    emotion\n",
       "0   0      anger\n",
       "1   1    disgust\n",
       "2   2  happiness\n",
       "3   3       fear\n",
       "4   4       fear"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger        421\n",
       "fear         416\n",
       "happiness    263\n",
       "sadness      158\n",
       "disgust      140\n",
       "surprise      38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences of each emotion\n",
    "emotion_counts = submission_df['emotion'].value_counts()\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/pre_trained_embeddings.h1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/pre_trained_embeddings.h1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./Models/pre_trained_embeddings.h1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression predictions have been saved to pretrained_predictions_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to CSV\n",
    "submission_df.to_csv('./Kaggle/Datasets multiclass/pretrained_predictions_2.csv', index=False)\n",
    "print(\"Logistic Regression predictions have been saved to pretrained_predictions_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
