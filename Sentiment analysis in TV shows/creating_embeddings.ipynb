{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\neilr\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickle file\n",
    "features = pd.read_pickle('./Datasets/feature_extraction_full.pkl')\n",
    "\n",
    "# Filter out rows where the emotion is \"neutral\"\n",
    "filtered_features = features[features['emotion'] != 'neutral']\n",
    "filtered_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(filtered_features['sentence'])\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "tokenized_sentences = tokenizer.texts_to_sequences(filtered_features['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "word2vec_model_custom = Word2Vec(sentences=tokenized_sentences, vector_size=300, window=5, min_count=1, sg=1, workers=4)\n",
    "X = tokenized_sentences\n",
    "y = filtered_features['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_length = 30  # Adjust according to your maximum sequence length\n",
    "X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "num_classes = len(np.unique(y_train_encoded))\n",
    "y_train_encoded_onehot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test_encoded_onehot = to_categorical(y_test_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map words to their corresponding word vectors in the custom Word2Vec model\n",
    "embedding_matrix_custom = np.zeros((vocab_size + 1, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec_model_custom.wv:\n",
    "        embedding_matrix_custom[i] = word2vec_model_custom.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\neilr\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size + 1, output_dim=300, input_length=max_sequence_length, weights=[embedding_matrix_custom], trainable=False))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\neilr\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\neilr\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\neilr\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "17673/17673 [==============================] - 135s 8ms/step - loss: 1.2114 - accuracy: 0.4182 - val_loss: 1.2109 - val_accuracy: 0.4247\n",
      "Epoch 2/10\n",
      "17673/17673 [==============================] - 190s 11ms/step - loss: 1.2097 - accuracy: 0.4206 - val_loss: 1.2105 - val_accuracy: 0.4247\n",
      "Epoch 3/10\n",
      "17673/17673 [==============================] - 198s 11ms/step - loss: 1.2103 - accuracy: 0.4213 - val_loss: 1.2109 - val_accuracy: 0.4247\n",
      "Epoch 4/10\n",
      "17673/17673 [==============================] - 199s 11ms/step - loss: 1.2100 - accuracy: 0.4205 - val_loss: 1.2107 - val_accuracy: 0.4247\n",
      "Epoch 5/10\n",
      "17673/17673 [==============================] - 211s 12ms/step - loss: 1.2093 - accuracy: 0.4216 - val_loss: 1.2106 - val_accuracy: 0.4247\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_padded, y_train_encoded_onehot, epochs=10, batch_size=16, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2762/2762 [==============================] - 29s 10ms/step - loss: 1.2085 - accuracy: 0.4235\n",
      "Test accuracy: 0.42352741956710815\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy on test set\n",
    "test_loss, test_acc = model.evaluate(X_test_padded, y_test_encoded_onehot)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Predict on Kaggle test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Girls are happy when they get flowers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>His jaw dropped in disbelief when he saw the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sometimes the ugly stench makes me wanna throw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The foul odor from the garbage bin was disgust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I can’t believe it, they lost the game in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence\n",
       "0   0              Girls are happy when they get flowers\n",
       "1   1  His jaw dropped in disbelief when he saw the p...\n",
       "2   2  Sometimes the ugly stench makes me wanna throw...\n",
       "3   3  The foul odor from the garbage bin was disgust...\n",
       "4   4  I can’t believe it, they lost the game in the ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading kaggle test file\n",
    "file_path = \"C:/Users/neilr/Documents/BUAS year 2/Block C/2023-24c-fai2-adsai-neildaniel221270/Kaggle/Datasets multiclass/test (kaggle).csv\"\n",
    "test_kaggle = pd.read_csv(file_path, sep='\\t')\n",
    "test_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data from Kaggle test set\n",
    "X_test_kaggle = test_kaggle['sentence']\n",
    "sequences_kaggle = tokenizer.texts_to_sequences(X_test_kaggle)\n",
    "padded_sequences_kaggle = pad_sequences(sequences_kaggle, padding='post', maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict emotions on Kaggle test set\n",
    "y_pred_kaggle = model.predict(padded_sequences_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02568394, 0.00366002, 0.09627504, 0.4285193 , 0.40245146,\n",
       "        0.04341031],\n",
       "       [0.02568394, 0.00366002, 0.09627504, 0.4285193 , 0.40245146,\n",
       "        0.04341031],\n",
       "       [0.02568394, 0.00366002, 0.09627504, 0.4285193 , 0.40245146,\n",
       "        0.04341031],\n",
       "       ...,\n",
       "       [0.02568394, 0.00366002, 0.09627504, 0.4285193 , 0.40245146,\n",
       "        0.04341031],\n",
       "       [0.02568394, 0.00366002, 0.09627504, 0.4285193 , 0.40245146,\n",
       "        0.04341031],\n",
       "       [0.02568394, 0.00366002, 0.09627504, 0.4285193 , 0.40245146,\n",
       "        0.04341031]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert predicted probabilities to emotions\n",
    "def get_emotion(pred):\n",
    "    emotions = ['happiness', 'surprise', 'sadness', 'anger', 'fear', 'disgust']\n",
    "    return emotions[np.argmax(pred)]\n",
    "\n",
    "\n",
    "# Convert predicted probabilities to emotions for Kaggle test set\n",
    "predicted_emotions = [get_emotion(pred) for pred in y_pred_kaggle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id emotion\n",
       "0   0   anger\n",
       "1   1   anger\n",
       "2   2   anger\n",
       "3   3   anger\n",
       "4   4   anger"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for submission\n",
    "submission_df = pd.DataFrame({'id': test_kaggle['id'], 'emotion': predicted_emotions})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger    1436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences of each emotion\n",
    "emotion_counts = submission_df['emotion'].value_counts()\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN predictions have been saved to created_embeddings_rnn_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to CSV\n",
    "submission_df.to_csv('./Kaggle/Datasets multiclass/created_embeddings_rnn_predictions.csv', index=False)\n",
    "print(\"RNN predictions have been saved to created_embeddings_rnn_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
