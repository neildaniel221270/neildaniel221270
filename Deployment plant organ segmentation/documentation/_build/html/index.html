<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Welcome to Computer Vision 3’s documentation! &#8212; Computer Vision 3 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=12dfc556" />
    <script src="_static/documentation_options.js?v=8d563738"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="data_loading Module" href="data_loading.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="welcome-to-computer-vision-3-s-documentation">
<h1>Welcome to Computer Vision 3’s documentation!<a class="headerlink" href="#welcome-to-computer-vision-3-s-documentation" title="Link to this heading">¶</a></h1>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="data_loading.html">data_loading Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="data_loading.html#data_loading.load_data_generators"><code class="docutils literal notranslate"><span class="pre">load_data_generators()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="data_loading.html#data_loading.validate_dataset"><code class="docutils literal notranslate"><span class="pre">validate_dataset()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">data_preprocessing Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="data_preprocessing.html#data_preprocessing.extract_roi"><code class="docutils literal notranslate"><span class="pre">extract_roi()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="data_preprocessing.html#data_preprocessing.preprocess_images"><code class="docutils literal notranslate"><span class="pre">preprocess_images()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="evaluation_metrics.html">evaluation_metrics Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="evaluation_metrics.html#evaluation_metrics.f1"><code class="docutils literal notranslate"><span class="pre">f1()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="evaluation_metrics.html#evaluation_metrics.iou"><code class="docutils literal notranslate"><span class="pre">iou()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="instance_segmentation.html">instance_segmentation Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="instance_segmentation.html#instance_segmentation.segment_instances"><code class="docutils literal notranslate"><span class="pre">segment_instances()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="landmarks_detection.html">landmarks_detection Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="landmarks_detection.html#landmarks_detection.detect_landmarks"><code class="docutils literal notranslate"><span class="pre">detect_landmarks()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main.html">main Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main.html#main.infer"><code class="docutils literal notranslate"><span class="pre">infer()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="main.html#main.predict_using_custom_model"><code class="docutils literal notranslate"><span class="pre">predict_using_custom_model()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="main.html#main.predict_using_primary_model"><code class="docutils literal notranslate"><span class="pre">predict_using_primary_model()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="main.html#main.train"><code class="docutils literal notranslate"><span class="pre">train()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="main.html#main.train_new_model"><code class="docutils literal notranslate"><span class="pre">train_new_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mask_prediction.html">mask_prediction Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="mask_prediction.html#mask_prediction.predict_mask"><code class="docutils literal notranslate"><span class="pre">predict_mask()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_creation.html">model_creation Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_creation.html#model_creation.build_model"><code class="docutils literal notranslate"><span class="pre">build_model()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="model_creation.html#model_creation.build_unet_a"><code class="docutils literal notranslate"><span class="pre">build_unet_a()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="model_creation.html#model_creation.build_unet_b"><code class="docutils literal notranslate"><span class="pre">build_unet_b()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="model_creation.html#model_creation.load_pretrained_model"><code class="docutils literal notranslate"><span class="pre">load_pretrained_model()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="model_creation.html#model_creation.save_model"><code class="docutils literal notranslate"><span class="pre">save_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_evaluation.html">model_evaluation Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_evaluation.html#model_evaluation.evaluate_model"><code class="docutils literal notranslate"><span class="pre">evaluate_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_training.html">model_training Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_training.html#model_training.hyperparameter_search"><code class="docutils literal notranslate"><span class="pre">hyperparameter_search()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="model_training.html#model_training.save_model"><code class="docutils literal notranslate"><span class="pre">save_model()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="model_training.html#model_training.train_model"><code class="docutils literal notranslate"><span class="pre">train_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="root_length_measurement.html">root_length_measurement Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="root_length_measurement.html#root_length_measurement.measure_root_lengths"><code class="docutils literal notranslate"><span class="pre">measure_root_lengths()</span></code></a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Link to this heading">¶</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</section>
<section id="module-data_loading">
<span id="project-modules"></span><h1>Project Modules<a class="headerlink" href="#module-data_loading" title="Link to this heading">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="data_loading.load_data_generators">
<span class="sig-prename descclassname"><span class="pre">data_loading.</span></span><span class="sig-name descname"><span class="pre">load_data_generators</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_loading.load_data_generators" title="Link to this definition">¶</a></dt>
<dd><p>Load data generators for training, validation, and testing datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset_path</strong> (<em>str</em>) – Path to the dataset directory.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Size of the data batches, defaults to 16.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing generators and lengths for training, testing, and validation datasets.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Neil Ross Daniel</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function can be used to load data generators for images and masks in training, validation, and testing datasets.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">load_data_generators</span>

<span class="c1"># Set dataset path</span>
<span class="n">dataset_path</span> <span class="o">=</span> <span class="s1">&#39;/path/to/dataset&#39;</span>

<span class="c1"># Load data generators</span>
<span class="p">(</span><span class="n">train_gen</span><span class="p">,</span> <span class="n">train_len</span><span class="p">),</span> <span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">test_len</span><span class="p">),</span> <span class="p">(</span><span class="n">val_gen</span><span class="p">,</span> <span class="n">val_len</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_data_generators</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="c1"># Iterate through the training generator</span>
<span class="k">for</span> <span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_masks</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_gen</span><span class="p">:</span>
    <span class="c1"># Your training code here</span>
    <span class="k">pass</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<p>The function performs the following steps:</p>
<ol class="arabic simple">
<li><p>Creates an image data generator for training images with rescaling and horizontal flipping.</p></li>
<li><p>Creates an image data generator for training masks with horizontal flipping.</p></li>
<li><p>Creates a zip generator for training images and masks.</p></li>
<li><p>Creates an image data generator for test images with rescaling.</p></li>
<li><p>Creates an image data generator for test masks.</p></li>
<li><p>Creates a zip generator for test images and masks.</p></li>
<li><p>Creates an image data generator for validation images with rescaling.</p></li>
<li><p>Creates an image data generator for validation masks.</p></li>
<li><p>Creates a zip generator for validation images and masks.</p></li>
</ol>
<p>The function returns a tuple containing three tuples:
- (train_generator, train_length)
- (test_generator, test_length)
- (val_generator, val_length)</p>
<p>Each generator is a zip object combining image and mask data. The lengths indicate the number of batches available in each generator.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="data_loading.validate_dataset">
<span class="sig-prename descclassname"><span class="pre">data_loading.</span></span><span class="sig-name descname"><span class="pre">validate_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_loading.validate_dataset" title="Link to this definition">¶</a></dt>
<dd><p>Validate the structure and contents of the dataset directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dataset_path</strong> (<em>str</em>) – Path to the dataset directory.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>AssertionError</strong> – If the dataset path or any required subfolder does not exist,
or if any required subfolder is empty.</p>
</dd>
<dt class="field-odd">Author<span class="colon">:</span></dt>
<dd class="field-odd"><p>Neil Ross Daniel</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function can be used to ensure that the dataset directory contains the required structure
and is not empty.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">validate_dataset</span>

<span class="c1"># Set dataset path</span>
<span class="n">dataset_path</span> <span class="o">=</span> <span class="s1">&#39;/path/to/dataset&#39;</span>

<span class="c1"># Validate the dataset structure and contents</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">validate_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset is valid.&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset validation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<p>The function performs the following steps:</p>
<ol class="arabic simple">
<li><p>Checks if the dataset path exists.</p></li>
<li><p>Checks if the ‘images’ and ‘masks’ subfolders exist within the dataset path.</p></li>
<li><p>Checks if the ‘train’, ‘test’, and ‘val’ subfolders exist within both the ‘images’ and ‘masks’ subfolders.</p></li>
<li><p>Ensures that each of the ‘train’, ‘test’, and ‘val’ subfolders is not empty.</p></li>
</ol>
<p>The function raises an <cite>AssertionError</cite> if any of these checks fail, providing a descriptive error message.</p>
</dd></dl>

<dl class="py function" id="module-data_preprocessing">
<dt class="sig sig-object py" id="data_preprocessing.extract_roi">
<span class="sig-prename descclassname"><span class="pre">data_preprocessing.</span></span><span class="sig-name descname"><span class="pre">extract_roi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_preprocessing.extract_roi" title="Link to this definition">¶</a></dt>
<dd><p>Extract the region of interest (ROI) from an image by identifying the largest contour,
which is assumed to be the Petri dish, and cropping the image accordingly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>image</strong> (<em>numpy.ndarray</em>) – Input image from which to extract the ROI.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the cropped ROI image and the coordinates (x, y) and dimensions (width, height) of the bounding box.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[numpy.ndarray, int, int, int, int]</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Neil Ross Daniel</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function can be used to extract the region of interest (ROI) from an image by identifying the largest contour.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">extract_roi</span>

<span class="c1"># Load an image</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;petri_dish_image.png&#39;</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Extract the ROI</span>
<span class="n">roi</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">extract_roi</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># Display the original image and the ROI</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Extracted ROI&#39;</span><span class="p">,</span> <span class="n">roi</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<p>The function performs the following steps:</p>
<ol class="arabic simple">
<li><p>Thresholds the input image to a binary image using Otsu’s method.</p></li>
<li><p>Finds contours in the binary image.</p></li>
<li><p>Identifies the largest contour, assuming it to be the Petri dish.</p></li>
<li><p>Calculates the bounding box of the largest contour.</p></li>
<li><p>Crops the image to the bounding box with some padding to ensure the whole Petri dish is included.</p></li>
<li><p>Adjusts the bounding box to get a square ROI based on the largest side.</p></li>
<li><p>Crops the image to the adjusted ROI.</p></li>
</ol>
<p>The function returns a tuple containing:
- <cite>roi</cite>: The cropped region of interest image.
- <cite>x</cite>: The x-coordinate of the top-left corner of the bounding box.
- <cite>y</cite>: The y-coordinate of the top-left corner of the bounding box.
- <cite>w</cite>: The width of the bounding box.
- <cite>h</cite>: The height of the bounding box.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="data_preprocessing.preprocess_images">
<span class="sig-prename descclassname"><span class="pre">data_preprocessing.</span></span><span class="sig-name descname"><span class="pre">preprocess_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_preprocessing.preprocess_images" title="Link to this definition">¶</a></dt>
<dd><p>Preprocess raw images and masks by extracting regions of interest (ROI), resizing, patchifying,
and distributing them into train, test, and validation subsets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset_path</strong> (<em>str</em>) – Path to the dataset directory containing raw images and masks.</p></li>
<li><p><strong>scaling_factor</strong> (<em>float</em><em>, </em><em>optional</em>) – Factor by which to scale the images and masks, defaults to 1 (no scaling).</p></li>
<li><p><strong>test_size</strong> (<em>float</em><em>, </em><em>optional</em>) – Proportion of the dataset to include in the test split, defaults to 0.2.</p></li>
<li><p><strong>val_size</strong> (<em>float</em><em>, </em><em>optional</em>) – Proportion of the training set to include in the validation split, defaults to 0.1.</p></li>
<li><p><strong>patch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Size of the patches to divide the images and masks into, defaults to 256.</p></li>
</ul>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Neil Ross Daniel</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function can be used to preprocess and organize a dataset of raw images and masks for machine learning tasks.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">preprocess_images</span>

<span class="c1"># Set dataset path</span>
<span class="n">dataset_path</span> <span class="o">=</span> <span class="s1">&#39;/path/to/dataset&#39;</span>

<span class="c1"># Preprocess the images</span>
<span class="n">preprocess_images</span><span class="p">(</span>
    <span class="n">dataset_path</span><span class="p">,</span>
    <span class="n">scaling_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">val_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">patch_size</span><span class="o">=</span><span class="mi">256</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<p>The function performs the following steps:</p>
<ol class="arabic simple">
<li><p>Collects all image file paths from the ‘images_raw’ directory.</p></li>
<li><p>Splits the dataset into train, test, and validation sets.</p></li>
<li><p>Creates the necessary output directories for train, test, and validation subsets.</p></li>
<li><p>Distributes and processes images and their corresponding masks into the appropriate subsets:
- Extracts the ROI from each image using the <cite>extract_roi</cite> function.
- Resizes the images and masks.
- Pads the images and masks to ensure they can be evenly divided into patches.
- Scales the images and masks if a scaling factor is provided.
- Divides the images and masks into patches of the specified size.
- Saves the patches into the corresponding subset directories.</p></li>
<li><p>Deletes the ‘images_raw’ and ‘masks_raw’ directories and their contents.</p></li>
</ol>
<p>The function returns <cite>None</cite>.</p>
</dd></dl>

<dl class="py function" id="module-evaluation_metrics">
<dt class="sig sig-object py" id="evaluation_metrics.f1">
<span class="sig-prename descclassname"><span class="pre">evaluation_metrics.</span></span><span class="sig-name descname"><span class="pre">f1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#evaluation_metrics.f1" title="Link to this definition">¶</a></dt>
<dd><p>Compute the F1 score metric for binary classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<em>keras.tensor.Tensor</em>) – True labels.</p></li>
<li><p><strong>y_pred</strong> (<em>keras.tensor.Tensor</em>) – Predicted labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>F1 score value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>keras.tensor.Tensor</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Rens van den Berg</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function calculates the F1 score for binary classification tasks.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">f1</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">f1_score</span><span class="p">))</span>  <span class="c1"># Output: 0.6666667</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<p>The function first defines two helper functions:</p>
<ul class="simple">
<li><p><cite>recall_m</cite>: Computes the recall metric.</p></li>
<li><p><cite>precision_m</cite>: Computes the precision metric.</p></li>
</ul>
<p>The F1 score is then computed as the harmonic mean of precision and recall.</p>
<p>The function returns the F1 score as a Keras tensor.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="evaluation_metrics.iou">
<span class="sig-prename descclassname"><span class="pre">evaluation_metrics.</span></span><span class="sig-name descname"><span class="pre">iou</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#evaluation_metrics.iou" title="Link to this definition">¶</a></dt>
<dd><p>Compute the Intersection over Union (IoU) metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<em>keras.tensor.Tensor</em>) – True labels.</p></li>
<li><p><strong>y_pred</strong> (<em>keras.tensor.Tensor</em>) – Predicted labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>IoU score value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>keras.tensor.Tensor</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Rens van den Berg</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function calculates the Intersection over Union (IoU) for evaluating the accuracy of an object detector on a particular dataset.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">iou</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]]])</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]]])</span>

<span class="n">iou_score</span> <span class="o">=</span> <span class="n">iou</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">iou_score</span><span class="p">))</span>  <span class="c1"># Output: 0.33333334</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<p>The function defines a helper function <cite>f</cite> that calculates the IoU for each image in the batch. The IoU is computed as the ratio of the intersection area to the union area of the true and predicted labels.</p>
<p>The function returns the mean IoU score across the batch as a Keras tensor.</p>
</dd></dl>

<dl class="py function" id="module-instance_segmentation">
<dt class="sig sig-object py" id="instance_segmentation.segment_instances">
<span class="sig-prename descclassname"><span class="pre">instance_segmentation.</span></span><span class="sig-name descname"><span class="pre">segment_instances</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#instance_segmentation.segment_instances" title="Link to this definition">¶</a></dt>
<dd><p>Segment instances in a given binary mask using morphological operations and the watershed algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mask</strong> (<em>numpy.ndarray</em>) – Input binary mask where instances are to be segmented.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A labeled mask where each instance has a unique label.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Neil Ross Daniel</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function can be used to segment individual instances from a binary mask using a combination of morphological operations and connected components analysis.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">segment_instances</span>

<span class="c1"># Load a binary mask image</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;binary_mask.png&#39;</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Segment instances in the mask</span>
<span class="n">labeled_mask</span> <span class="o">=</span> <span class="n">segment_instances</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="c1"># Save or display the result</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s1">&#39;labeled_mask.png&#39;</span><span class="p">,</span> <span class="n">labeled_mask</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Labeled Mask&#39;</span><span class="p">,</span> <span class="n">labeled_mask</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<p>The function performs the following steps:</p>
<ol class="arabic simple">
<li><p>Applies morphological closing operation to the input mask using a rectangular structuring element.</p></li>
<li><p>Detects connected components in the processed mask.</p></li>
<li><p>Filters components based on defined width and height thresholds.</p></li>
<li><p>Sorts the components by area and keeps the top 5 largest components.</p></li>
<li><p>Checks if the centroids of the top components fall within expected plant locations.</p></li>
<li><p>Labels the top components in the output image with unique colors.</p></li>
</ol>
<p>The function returns an output image where each segmented instance is labeled with a unique color.</p>
</dd></dl>

<dl class="py function" id="module-landmarks_detection">
<dt class="sig sig-object py" id="landmarks_detection.detect_landmarks">
<span class="sig-prename descclassname"><span class="pre">landmarks_detection.</span></span><span class="sig-name descname"><span class="pre">detect_landmarks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#landmarks_detection.detect_landmarks" title="Link to this definition">¶</a></dt>
<dd><p>Detect landmarks such as primary root start and end points, and lateral root tips
from the provided mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mask</strong> (<em>numpy.ndarray</em>) – Binary mask representing the segmented instances.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of dictionaries containing the coordinates of primary root start and end points,
and lateral root tips.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[dict]</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Rens van den Berg</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function can be used to detect landmarks such as the primary root start and end points,
and lateral root tips from a binary mask of segmented instances.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">detect_landmarks</span>

<span class="c1"># Load a binary mask image</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;binary_mask.png&#39;</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

<span class="c1"># Detect landmarks in the mask</span>
<span class="n">landmarks</span> <span class="o">=</span> <span class="n">detect_landmarks</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="c1"># Print detected landmarks</span>
<span class="k">for</span> <span class="n">plant</span> <span class="ow">in</span> <span class="n">landmarks</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Primary Root Start:&quot;</span><span class="p">,</span> <span class="n">plant</span><span class="p">[</span><span class="s2">&quot;primary_root_start&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Primary Root End:&quot;</span><span class="p">,</span> <span class="n">plant</span><span class="p">[</span><span class="s2">&quot;primary_root_end&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Lateral Root Tips:&quot;</span><span class="p">,</span> <span class="n">plant</span><span class="p">[</span><span class="s2">&quot;l_root_tips&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<p>The function performs the following steps:</p>
<ol class="arabic simple">
<li><p>Segments the instances in the input mask using the <cite>segment_instances</cite> function.</p></li>
<li><p>Converts the segmented mask to a binary format.</p></li>
<li><p>Applies skeletonization to the binary mask.</p></li>
<li><p>Summarizes the skeleton data to extract root landmarks.</p></li>
<li><p>Identifies and records the coordinates of primary root start and end points, and lateral root tips.</p></li>
<li><p>Returns a list of dictionaries containing the detected landmarks for each plant.</p></li>
</ol>
<p>The function returns a list of dictionaries, where each dictionary contains:
- <cite>primary_root_start</cite>: Coordinates of the primary root start point.
- <cite>primary_root_end</cite>: Coordinates of the primary root end point.
- <cite>l_root_tips</cite>: List of coordinates for the lateral root tips.</p>
</dd></dl>

<dl class="py function" id="module-main">
<dt class="sig sig-object py" id="main.infer">
<span class="sig-prename descclassname"><span class="pre">main.</span></span><span class="sig-name descname"><span class="pre">infer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_path:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_model_name:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">&lt;typer.models.ArgumentInfo</span> <span class="pre">object&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#main.infer" title="Link to this definition">¶</a></dt>
<dd><p>Perform inference on an image using a specified custom model or the primary model if no custom model is specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img_path</strong> (<em>str</em>) – Path to the input image.</p></li>
<li><p><strong>custom_model_name</strong> (<em>str</em><em>, </em><em>optional</em>) – Name of the custom-trained model to load.</p></li>
</ul>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Michal Dziechciarz</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function allows performing inference using either a custom model or the primary pre-trained model.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">infer</span>

<span class="n">infer</span><span class="p">(</span><span class="s2">&quot;path/to/my_image.png&quot;</span><span class="p">,</span> <span class="s2">&quot;my_custom_model&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>If <cite>custom_model_name</cite> is provided and the model exists, it uses the custom model for inference.</p></li>
<li><p>If <cite>custom_model_name</cite> is not provided, it uses the primary model for inference.</p></li>
<li><p>Displays the original image and segmentation mask, and outputs the detected landmarks and root lengths.</p></li>
</ul>
<p>This function provides flexibility in deploying both custom-trained and primary models for inference.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="main.predict_using_custom_model">
<span class="sig-prename descclassname"><span class="pre">main.</span></span><span class="sig-name descname"><span class="pre">predict_using_custom_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_model_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#main.predict_using_custom_model" title="Link to this definition">¶</a></dt>
<dd><p>Perform inference using a custom-trained model on a given image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image_path</strong> (<em>str</em>) – Path to the input image.</p></li>
<li><p><strong>custom_model_name</strong> (<em>str</em>) – Name of the custom-trained model to load.</p></li>
</ul>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Michal Dziechciarz</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function loads a custom-trained model and performs inference on a specific image.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">predict_using_custom_model</span>

<span class="n">predict_using_custom_model</span><span class="p">(</span><span class="s2">&quot;path/to/my_image.png&quot;</span><span class="p">,</span> <span class="s2">&quot;my_custom_model&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Loads a pre-trained custom model from the <cite>user_custom_models</cite> directory.</p></li>
<li><p>Uses the model to predict a segmentation mask, detect landmarks, and measure root lengths from the input image.</p></li>
<li><p>Displays the original image, segmentation mask, and outputs the detected landmarks and root lengths.</p></li>
</ul>
<p>This function is suitable for deploying and testing custom-trained models on new images.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="main.predict_using_primary_model">
<span class="sig-prename descclassname"><span class="pre">main.</span></span><span class="sig-name descname"><span class="pre">predict_using_primary_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#main.predict_using_primary_model" title="Link to this definition">¶</a></dt>
<dd><p>Perform inference using the primary pre-trained model on a given image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>image_path</strong> (<em>str</em>) – Path to the input image.</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Michal Dziechciarz</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function loads the primary pre-trained model and performs inference on a specific image.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">predict_using_primary_model</span>

<span class="n">predict_using_primary_model</span><span class="p">(</span><span class="s2">&quot;path/to/my_image.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Loads the pre-trained primary model from the <cite>models</cite> directory.</p></li>
<li><p>Uses the model to predict a segmentation mask, detect landmarks, and measure root lengths from the input image.</p></li>
<li><p>Displays the original image, segmentation mask, and outputs the detected landmarks and root lengths.</p></li>
</ul>
<p>This function is suitable for deploying and testing the primary model on new images.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="main.train">
<span class="sig-prename descclassname"><span class="pre">main.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_model_name:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dataset_path:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">&lt;typer.models.OptionInfo</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">&lt;typer.models.OptionInfo</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">&lt;typer.models.OptionInfo</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">&lt;typer.models.OptionInfo</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_filters:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">&lt;typer.models.OptionInfo</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">&lt;typer.models.OptionInfo</span> <span class="pre">object&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#main.train" title="Link to this definition">¶</a></dt>
<dd><p>Train a new model with optional custom dataset and hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>new_model_name</strong> (<em>str</em>) – Name of the new model to be saved.</p></li>
<li><p><strong>custom_dataset_path</strong> (<em>str</em><em>, </em><em>optional</em>) – Path to a custom dataset directory.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Learning rate for training.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Batch size for training.</p></li>
<li><p><strong>dropout_rate</strong> (<em>str</em><em>, </em><em>optional</em>) – Dropout rates for training, comma-separated.</p></li>
<li><p><strong>num_filters</strong> (<em>str</em><em>, </em><em>optional</em>) – Number of filters for each layer, comma-separated.</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of epochs for training.</p></li>
</ul>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Michal Dziechciarz</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function trains a new model with specified custom dataset and hyperparameters, if provided.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">train</span>

<span class="n">train</span><span class="p">(</span>
    <span class="n">new_model_name</span><span class="o">=</span><span class="s2">&quot;my_custom_model&quot;</span><span class="p">,</span>
    <span class="n">custom_dataset_path</span><span class="o">=</span><span class="s2">&quot;my_custom_dataset&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">dropout_rate</span><span class="o">=</span><span class="s2">&quot;0.3,0.3,0.3&quot;</span><span class="p">,</span>
    <span class="n">num_filters</span><span class="o">=</span><span class="s2">&quot;64,128,256&quot;</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Checks if the new model name is available.</p></li>
<li><p>If <cite>custom_dataset_path</cite> is provided, validates the dataset and preprocesses the images.</p></li>
<li><p>If no hyperparameters are provided, performs hyperparameter search.</p></li>
<li><p>Otherwise, trains the model with the provided custom hyperparameters.</p></li>
</ul>
<p>The trained model is saved in the directory <cite>user_custom_models</cite> with the specified <cite>new_model_name</cite>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="main.train_new_model">
<span class="sig-prename descclassname"><span class="pre">main.</span></span><span class="sig-name descname"><span class="pre">train_new_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_model_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dataset_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_hyperparameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#main.train_new_model" title="Link to this definition">¶</a></dt>
<dd><p>Train a new model using either a custom dataset or a default testing dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>new_model_name</strong> (<em>str</em>) – Name of the new model to be saved.</p></li>
<li><p><strong>custom_dataset_path</strong> (<em>str</em><em>, </em><em>optional</em>) – Path to a custom dataset directory.</p></li>
<li><p><strong>custom_hyperparameters</strong> (<em>dict</em><em>, </em><em>optional</em>) – Dictionary containing custom hyperparameters for model training.</p></li>
</ul>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Rens van den Berg</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function allows training a new model either with a custom dataset or a default testing dataset.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">train_new_model</span>

<span class="n">train_new_model</span><span class="p">(</span><span class="s2">&quot;my_custom_model&quot;</span><span class="p">,</span> <span class="s2">&quot;my_custom_dataset&quot;</span><span class="p">,</span> <span class="n">custom_hyperparameters</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>If <cite>custom_dataset_path</cite> is provided, it preprocesses images and loads data generators from the custom dataset.</p></li>
<li><p>If <cite>custom_hyperparameters</cite> is provided, it trains the model with custom hyperparameters.</p></li>
<li><p>Otherwise, it performs hyperparameter search to find the best model configuration.</p></li>
</ul>
<p>The trained model is saved in the directory <cite>user_custom_models</cite> with the specified <cite>new_model_name</cite>.</p>
</dd></dl>

<dl class="py function" id="module-mask_prediction">
<dt class="sig sig-object py" id="mask_prediction.predict_mask">
<span class="sig-prename descclassname"><span class="pre">mask_prediction.</span></span><span class="sig-name descname"><span class="pre">predict_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_img_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mask_prediction.predict_mask" title="Link to this definition">¶</a></dt>
<dd><p>Predict the segmentation mask for an input image using the provided model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.models.Model</em>) – The pre-trained model used for prediction.</p></li>
<li><p><strong>input_img_path</strong> (<em>str</em>) – Path to the input image.</p></li>
<li><p><strong>patch_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default is 256</em><em>)</em>) – Size of the patches for model prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Predicted segmentation mask.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Michal Dziechciarz</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function predicts a segmentation mask for an input image using a pre-trained model.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">predict_mask</span><span class="p">,</span> <span class="n">load_pretrained_model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">load_pretrained_model</span><span class="p">(</span><span class="s2">&quot;models/primary.h5&quot;</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">predict_mask</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;path/to/my_image.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Loads the input image in grayscale.</p></li>
<li><p>Extracts the region of interest (ROI) based on predefined coordinates and dimensions.</p></li>
<li><p>Pads the image to ensure dimensions are divisible by the patch size.</p></li>
<li><p>Splits the image into patches, performs predictions on each patch, and reassembles the patches into a full mask.</p></li>
<li><p>Applies a threshold to the predicted mask to binarize it.</p></li>
</ul>
<p>This function is useful for applying a pre-trained model to generate segmentation masks for input images.</p>
</dd></dl>

<dl class="py function" id="module-model_creation">
<dt class="sig sig-object py" id="model_creation.build_model">
<span class="sig-prename descclassname"><span class="pre">model_creation.</span></span><span class="sig-name descname"><span class="pre">build_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">IMG_HEIGHT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">IMG_WIDTH</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">IMG_CHANNELS</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_filters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">architecture</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'unet_a'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_creation.build_model" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="model_creation.build_unet_a">
<span class="sig-prename descclassname"><span class="pre">model_creation.</span></span><span class="sig-name descname"><span class="pre">build_unet_a</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">IMG_HEIGHT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">IMG_WIDTH</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">IMG_CHANNELS</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_filters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_creation.build_unet_a" title="Link to this definition">¶</a></dt>
<dd><p>Build a U-Net model for image segmentation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>IMG_HEIGHT</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default is 256</em><em>)</em>) – Height of the input images.</p></li>
<li><p><strong>IMG_WIDTH</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default is 256</em><em>)</em>) – Width of the input images.</p></li>
<li><p><strong>IMG_CHANNELS</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default is 1</em><em>)</em>) – Number of channels in the input images.</p></li>
<li><p><strong>num_filters</strong> (<em>list</em><em> of </em><em>int</em><em>, </em><em>optional</em>) – List of filter sizes for each convolutional layer.</p></li>
<li><p><strong>dropout_rate</strong> (<em>list</em><em> of </em><em>float</em><em>, </em><em>optional</em>) – List of dropout rates for each layer.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default is 1e-3</em><em>)</em>) – Learning rate for the optimizer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Compiled U-Net model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>keras.models.Model</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Michal Dziechciarz</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function builds a U-Net model with configurable parameters for image segmentation tasks.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">build_model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span>
    <span class="n">IMG_HEIGHT</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">IMG_WIDTH</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">IMG_CHANNELS</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_filters</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span>
    <span class="n">dropout_rate</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Constructs a U-Net model with a specified number of filters and dropout rates for each layer.</p></li>
<li><p>The contraction path consists of several Conv2D, Dropout, and MaxPooling2D layers.</p></li>
<li><p>The expansive path consists of Conv2DTranspose and Conv2D layers, with concatenations from the contraction path.</p></li>
<li><p>The model is compiled with a specified learning rate, binary cross-entropy loss, and metrics including accuracy, F1 score, and IoU.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="model_creation.build_unet_b">
<span class="sig-prename descclassname"><span class="pre">model_creation.</span></span><span class="sig-name descname"><span class="pre">build_unet_b</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">IMG_HEIGHT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">IMG_WIDTH</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">IMG_CHANNELS</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_filters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_creation.build_unet_b" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="model_creation.load_pretrained_model">
<span class="sig-prename descclassname"><span class="pre">model_creation.</span></span><span class="sig-name descname"><span class="pre">load_pretrained_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_creation.load_pretrained_model" title="Link to this definition">¶</a></dt>
<dd><p>Load a pre-trained model with custom objects.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_path</strong> (<em>str</em>) – Path to the pre-trained model file.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Loaded pre-trained model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>keras.models.Model</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Michal Dziechciarz</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function loads a pre-trained model with custom objects (F1 score and IoU metrics).</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">load_pretrained_model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">load_pretrained_model</span><span class="p">(</span><span class="s2">&quot;models/primary.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Loads the model from the specified file path.</p></li>
<li><p>Ensures custom metrics (F1 score and IoU) are available during model loading.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="model_creation.save_model">
<span class="sig-prename descclassname"><span class="pre">model_creation.</span></span><span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_creation.save_model" title="Link to this definition">¶</a></dt>
<dd><p>Save a trained model to a specified path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.models.Model</em>) – Trained model to be saved.</p></li>
<li><p><strong>path</strong> (<em>str</em>) – Path to save the model file.</p></li>
</ul>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Michal Dziechciarz</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function saves a trained Keras model to the specified file path.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">save_model</span>

<span class="n">save_model</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="s2">&quot;models/my_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Saves the model in the specified path.</p></li>
<li><p>Prints a success message upon saving the model.</p></li>
</ul>
</dd></dl>

<dl class="py function" id="module-model_evaluation">
<dt class="sig sig-object py" id="model_evaluation.evaluate_model">
<span class="sig-prename descclassname"><span class="pre">model_evaluation.</span></span><span class="sig-name descname"><span class="pre">evaluate_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mlflow</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_evaluation.evaluate_model" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the performance of a trained model on a test dataset.</p>
<p>This function calculates the Intersection over Union (IoU), accuracy, and F1 score of the model’s predictions
on the provided test dataset. The test dataset should contain images and corresponding ground truth masks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – Trained model to be evaluated.</p></li>
<li><p><strong>test_dataset_path</strong> (<em>str</em>) – Path to the directory containing the test dataset. The directory should have
subdirectories ‘images/images’ for test images and ‘masks/masks’ for ground truth masks.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary containing the IoU, accuracy, and F1 score of the model’s predictions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Stijn Heesters</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function evaluates the model’s performance on the test dataset and returns the evaluation metrics.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">evaluate_model</span>

<span class="n">test_dataset_path</span> <span class="o">=</span> <span class="s2">&quot;path/to/test_dataset&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_trained_model</span><span class="p">(</span><span class="s2">&quot;path/to/trained_model.h5&quot;</span><span class="p">)</span>
<span class="n">evaluation_metrics</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_dataset_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation_metrics</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Loads the test images and ground truth masks from the specified directory.</p></li>
<li><p>Makes predictions using the provided model.</p></li>
<li><p>Computes the IoU, accuracy, and F1 score for the model’s predictions.</p></li>
<li><p>Returns the evaluation metrics in a dictionary.</p></li>
</ul>
<p><strong>Dependencies:</strong></p>
<p>This function requires the following libraries:
- numpy
- glob
- os
- cv2 (OpenCV)
- keras
- sklearn.metrics (for accuracy_score)
- skimage.morphology (for skeletonize)
- networkx (for graph operations)
- skan (for skeleton analysis)</p>
<dl class="field-list simple">
<dt class="field-odd">Note<span class="colon">:</span></dt>
<dd class="field-odd"><p>Ensure that the input model is a trained keras model and the test dataset directory structure is correct.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function" id="module-model_training">
<dt class="sig sig-object py" id="model_training.hyperparameter_search">
<span class="sig-prename descclassname"><span class="pre">model_training.</span></span><span class="sig-name descname"><span class="pre">hyperparameter_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_training.hyperparameter_search" title="Link to this definition">¶</a></dt>
<dd><p>Perform hyperparameter search to find the best model configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_generator</strong> (<em>keras.utils.Sequence</em>) – Generator for training data.</p></li>
<li><p><strong>train_length</strong> (<em>int</em>) – Number of training samples per epoch.</p></li>
<li><p><strong>val_generator</strong> (<em>keras.utils.Sequence</em>) – Generator for validation data.</p></li>
<li><p><strong>val_length</strong> (<em>int</em>) – Number of validation samples per epoch.</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of epochs to train the models, defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Best model, training history, and best hyperparameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple(keras.models.Model, keras.callbacks.History, dict)</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function performs a hyperparameter search to find the best model configuration.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">hyperparameter_search</span>

<span class="n">best_model</span><span class="p">,</span> <span class="n">best_history</span><span class="p">,</span> <span class="n">best_hyperparameters</span> <span class="o">=</span> <span class="n">hyperparameter_search</span><span class="p">(</span>
    <span class="n">train_generator</span><span class="p">,</span> <span class="n">train_length</span><span class="p">,</span> <span class="n">val_generator</span><span class="p">,</span> <span class="n">val_length</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Trains multiple models with different hyperparameter configurations.</p></li>
<li><p>Returns the best model based on validation loss.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Author<span class="colon">:</span></dt>
<dd class="field-odd"><p>Michal Dziechciarz</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="model_training.save_model">
<span class="sig-prename descclassname"><span class="pre">model_training.</span></span><span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_training.save_model" title="Link to this definition">¶</a></dt>
<dd><p>Save a trained model to a specified path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.models.Model</em>) – Trained model to be saved.</p></li>
<li><p><strong>path</strong> (<em>str</em>) – Path to save the model file.</p></li>
</ul>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Rens van den Berg</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function saves a trained Keras model to the specified file path.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">save_model</span>

<span class="n">save_model</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="s2">&quot;models/my_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Saves the model in the specified path.</p></li>
<li><p>Prints a success message upon saving the model.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="model_training.train_model">
<span class="sig-prename descclassname"><span class="pre">model_training.</span></span><span class="sig-name descname"><span class="pre">train_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mlflow</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_training.train_model" title="Link to this definition">¶</a></dt>
<dd><p>Train a model using the provided training and validation data generators.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.models.Model</em>) – Keras model to be trained.</p></li>
<li><p><strong>train_generator</strong> (<em>keras.utils.Sequence</em>) – Generator for training data.</p></li>
<li><p><strong>train_length</strong> (<em>int</em>) – Number of training samples per epoch.</p></li>
<li><p><strong>val_generator</strong> (<em>keras.utils.Sequence</em>) – Generator for validation data.</p></li>
<li><p><strong>val_length</strong> (<em>int</em>) – Number of validation samples per epoch.</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of epochs to train the model, defaults to 100.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Batch size for training, defaults to 16.</p></li>
<li><p><strong>use_mlflow</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to log training details to MLflow, defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Trained model and training history.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple(keras.models.Model, keras.callbacks.History)</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function trains a Keras model using the specified training and validation data generators.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">train_model</span>

<span class="n">model</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">train_generator</span><span class="p">,</span>
    <span class="n">train_length</span><span class="p">,</span>
    <span class="n">val_generator</span><span class="p">,</span>
    <span class="n">val_length</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">use_mlflow</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Implements early stopping to avoid overfitting.</p></li>
<li><p>Logs training details to MLflow if specified.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Author<span class="colon">:</span></dt>
<dd class="field-odd"><p>Michal Dziechciarz</p>
</dd>
</dl>
</dd></dl>

<dl class="py function" id="module-root_length_measurement">
<dt class="sig sig-object py" id="root_length_measurement.measure_root_lengths">
<span class="sig-prename descclassname"><span class="pre">root_length_measurement.</span></span><span class="sig-name descname"><span class="pre">measure_root_lengths</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#root_length_measurement.measure_root_lengths" title="Link to this definition">¶</a></dt>
<dd><p>Measure the lengths of primary and lateral roots in the given mask.</p>
<p>This function analyzes the root system in the provided mask image, segments the roots, skeletonizes them,
and computes the lengths of primary and lateral roots. It returns a list of dictionaries with the x-coordinate
of the primary root start, the primary root length, and a list of lateral root lengths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mask</strong> (<em>numpy.ndarray</em>) – Input mask image where the root system needs to be analyzed.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of dictionaries containing the x-coordinate of the primary root start, the primary root length,
and a list of lateral root lengths.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of dict</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Stijn Heesters</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function measures the lengths of the primary and lateral roots in the given mask image.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">measure_root_lengths</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">root_lengths</span> <span class="o">=</span> <span class="n">measure_root_lengths</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">root_lengths</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Segments the input mask image to identify root instances.</p></li>
<li><p>Skeletonizes the segmented image to extract the root skeleton.</p></li>
<li><p>Constructs a graph from the skeleton to compute root lengths using Dijkstra’s algorithm.</p></li>
<li><p>Identifies the primary root as the longest path from the top to the bottom of the image.</p></li>
<li><p>Computes the lengths of lateral roots branching off from the primary root.</p></li>
</ul>
<p><strong>Dependencies:</strong></p>
<p>This function requires the following libraries:
- numpy
- networkx
- skimage.morphology
- skan</p>
<dl class="field-list simple">
<dt class="field-odd">Note<span class="colon">:</span></dt>
<dd class="field-odd"><p>Ensure that the input mask image is a binary image where roots are represented by non-zero values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function" id="module-model_registration">
<dt class="sig sig-object py" id="model_registration.register_if_IOU_above_threshold">
<span class="sig-prename descclassname"><span class="pre">model_registration.</span></span><span class="sig-name descname"><span class="pre">register_if_IOU_above_threshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_registration.register_if_IOU_above_threshold" title="Link to this definition">¶</a></dt>
<dd><p>Register the model if the IOU metric is above the given threshold.</p>
<p>This function reads the metrics from a JSON file and registers the model if the IOU (Intersection Over Union)
value is above the specified threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong> (<em>str</em>) – Path to the model file.</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Name to register the model under.</p></li>
<li><p><strong>metrics_path</strong> (<em>str</em>) – Path to the JSON file containing model metrics.</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) – IOU threshold value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
<dt class="field-even">Example<span class="colon">:</span></dt>
<dd class="field-even"><p></p></dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">register_if_IOU_above_threshold</span><span class="p">(</span><span class="s2">&quot;/path/to/model&quot;</span><span class="p">,</span> <span class="s2">&quot;my_model_name&quot;</span><span class="p">,</span> <span class="s2">&quot;/path/to/metrics&quot;</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Note<span class="colon">:</span></dt>
<dd class="field-odd"><p>Ensure that the metrics file exists at the specified path and contains an ‘iou’ key.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="model_registration.register_model">
<span class="sig-prename descclassname"><span class="pre">model_registration.</span></span><span class="sig-name descname"><span class="pre">register_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_registration.register_model" title="Link to this definition">¶</a></dt>
<dd><p>Register a model in the AzureML model registry.</p>
<p>This function registers a model in the AzureML model registry using the provided model path and name.
It uses <cite>ClientSecretCredential</cite> for authentication and <cite>MLClient</cite> to interact with the AzureML workspace.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong> (<em>str</em>) – Path to the model file.</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Name to register the model under.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Lea Bancovac</p>
</dd>
<dt class="field-odd">Example<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">register_model</span><span class="p">(</span><span class="s2">&quot;/path/to/model&quot;</span><span class="p">,</span> <span class="s2">&quot;my_model_name&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Note<span class="colon">:</span></dt>
<dd class="field-odd"><p>Ensure that the model file exists at the specified path and the credentials are correctly set up.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function" id="module-utils">
<dt class="sig sig-object py" id="utils.padder">
<span class="sig-prename descclassname"><span class="pre">utils.</span></span><span class="sig-name descname"><span class="pre">padder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.padder" title="Link to this definition">¶</a></dt>
<dd><p>Pad an input image so that its dimensions become divisible by a specified patch size.</p>
<p>This function adds padding around the input image to ensure its height and width
are multiples of the patch size. This is useful for processing images in patches
during tasks like image segmentation using models that require inputs of specific sizes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>numpy.ndarray</em><em>, </em><em>shape</em><em> (</em><em>H</em><em>, </em><em>W</em><em>, </em><em>C</em><em>)</em>) – Input image to be padded.</p></li>
<li><p><strong>patch_size</strong> (<em>int</em>) – Size of the patches the image will be divided into.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Padded image with dimensions divisible by patch_size.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>numpy.ndarray, shape (H_padded, W_padded, C)</p>
</dd>
</dl>
<p><strong>Usage:</strong></p>
<p>This function pads the input image so that its dimensions are divisible by the specified patch size.</p>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">your_module</span> <span class="kn">import</span> <span class="n">padder</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;input_image.png&quot;</span><span class="p">)</span>
<span class="n">patch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">padded_image</span> <span class="o">=</span> <span class="n">padder</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s2">&quot;padded_image.png&quot;</span><span class="p">,</span> <span class="n">padded_image</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Details:</strong></p>
<ul class="simple">
<li><p>Computes the required padding to make the image dimensions divisible by the patch size.</p></li>
<li><p>Adds padding evenly around the image.</p></li>
<li><p>Returns the padded image with dimensions (H_padded, W_padded, C).</p></li>
</ul>
<p><strong>Dependencies:</strong></p>
<p>This function requires the OpenCV library (<cite>cv2</cite>) for image manipulation.</p>
<dl class="field-list simple">
<dt class="field-odd">Note<span class="colon">:</span></dt>
<dd class="field-odd"><p>Ensure the input image has channels in the order (height, width, channels) for correct padding.</p>
</dd>
<dt class="field-even">Author<span class="colon">:</span></dt>
<dd class="field-even"><p>Lea Bancovac</p>
</dd>
</dl>
</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="#">Computer Vision 3</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="data_loading.html">data_loading Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preprocessing.html">data_preprocessing Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation_metrics.html">evaluation_metrics Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="instance_segmentation.html">instance_segmentation Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="landmarks_detection.html">landmarks_detection Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="main.html">main Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="mask_prediction.html">mask_prediction Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_creation.html">model_creation Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_evaluation.html">model_evaluation Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_training.html">model_training Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="root_length_measurement.html">root_length_measurement Module</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
      <li>Next: <a href="data_loading.html" title="next chapter">data_loading Module</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Michal Dziechciarz, Rens van den Berg, Stijn Heesters, Lea Bancovac, Neil Ross Daniel.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>